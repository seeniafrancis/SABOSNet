{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecafa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 28 11:13:17 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    64W / 275W |  13297MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   62C    P0   258W / 275W |  26102MiB / 40536MiB |     99%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   52C    P0    91W / 275W |  37488MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28b75bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchio\n",
      "  Downloading torchio-0.18.71-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 700 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torchio) (4.62.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from torchio) (1.6.3)\n",
      "Collecting SimpleITK!=2.0.*\n",
      "  Downloading SimpleITK-2.1.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.4 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from torchio) (8.0.3)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from torchio) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.8/site-packages (from torchio) (1.11.0a0+b6df043)\n",
      "Collecting humanize\n",
      "  Downloading humanize-3.13.1-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 9.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting nibabel\n",
      "  Downloading nibabel-3.2.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.13.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 10.5 MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.8/site-packages (from nibabel->torchio) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=14.3->nibabel->torchio) (3.0.5)\n",
      "Installing collected packages: wrapt, SimpleITK, nibabel, humanize, Deprecated, torchio\n",
      "Successfully installed Deprecated-1.2.13 SimpleITK-2.1.1 humanize-3.13.1 nibabel-3.2.1 torchio-0.18.71 wrapt-1.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcfe812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting monai\n",
      "  Downloading monai-0.8.0-202111251823-py3-none-any.whl (709 kB)\n",
      "\u001b[K     |████████████████████████████████| 709 kB 221 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from monai) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->monai) (3.10.0.2)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43264e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm\n",
    "import random\n",
    "import copy\n",
    "import torchio\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f50f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "t.backends.cudnn.enabled = True\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "#device = t.device(\"cuda:2\")\n",
    "\n",
    "device = t.device(\"cuda:0\")\n",
    "device1 = t.device(\"cuda:0\")\n",
    "device2 = t.device(\"cuda:0\")\n",
    "print (device)\n",
    "#device = \"cuda:0\"\n",
    "#device1 = \"cuda:0\"\n",
    "#device2 = \"cuda:1\"\n",
    "\n",
    "train_path = \"Data/train_data_tcia.pth\"\n",
    "test_path = \"Data/test_data_tcia.pth\"\n",
    "\n",
    "file_name = \"UNet_dice_log_tcia.txt\"\n",
    "file_name_1 = \"UNet_loss_log_tcia.txt\"\n",
    "file_name_2 = \"UNet_totalDice_log_tcia.txt\"\n",
    "\n",
    "epoch150_path_name = \"Weights/Unet_tcia_150.pth\"\n",
    "\n",
    "\n",
    "y_pred_path = \"OutputsTcia/Unetpred_tcia\"\n",
    "y_true_path = \"OutputsTcia/Unettrue_tcia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4e918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet Model with down sampling in each layer\n",
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,kernelSize=3):\n",
    "        super().__init__()\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.convblock1(x)\n",
    "        x=self.convblock2(x)\n",
    "        x=self.reluUnit(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.downConv  = nn.Sequential(\n",
    "            nn.Conv3d(1,32,kernel_size=3,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "        self.layer21 = nn.Sequential(\n",
    "            ConvBlock(32,40),\n",
    "            ConvBlock(40,40),\n",
    "            nn.Conv3d(40,40,kernel_size=3,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm3d(40),\n",
    "            nn.LeakyReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "        self.layer22 = nn.Sequential(\n",
    "            ConvBlock(40,48),\n",
    "            ConvBlock(48,48),\n",
    "            nn.Conv3d(48,48,kernel_size=3,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm3d(48),\n",
    "            nn.LeakyReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "        self.layer23 = ConvBlock(48,56)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x0=self.downConv(x)\n",
    "        x1=self.layer21(x0)\n",
    "        x2=self.layer22(x1)\n",
    "        x3=self.layer23(x2)\n",
    "        #print(x3.shape)\n",
    "        return x,x0,x1,x2,x3\n",
    "\n",
    "\n",
    "class Decoder_part1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer23 = nn.Sequential(\n",
    "            ConvBlock(56,56),\n",
    "            ConvBlock(56,48)\n",
    "        )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            ConvBlock(96,48),\n",
    "            ConvBlock(48,48),\n",
    "            ConvBlock(48,40)\n",
    "        )\n",
    "        self.layer21 = nn.Sequential(\n",
    "            ConvBlock(80,40),\n",
    "            ConvBlock(40,40),\n",
    "            ConvBlock(40,32)\n",
    "        )\n",
    "        self.layer20 = nn.Sequential(\n",
    "            ConvBlock(64,32),\n",
    "            ConvBlock(32,32)\n",
    "        )\n",
    "        self.transposeConv1 = nn.ConvTranspose3d(32,16,kernel_size=2,stride=2)\n",
    "        self.transposeConv1 = nn.ConvTranspose3d(32,16,kernel_size=2,stride=2)\n",
    "        self.transposeConv3 = nn.ConvTranspose3d(32,16,kernel_size=2,stride=2)\n",
    "        self.layer10 = nn.Conv3d(17,16,kernel_size=3,padding=1)\n",
    "\n",
    "    def forward(self,x,x0,x1,x2,x3):\n",
    "        \n",
    "        y=self.layer23(x3)\n",
    "        self.transposeConv1 = nn.ConvTranspose3d(48,48,kernel_size=2,stride=2)\n",
    "        y=t.cat([y,x2],dim=1)\n",
    "        y=self.layer22(y)\n",
    "        self.transposeConv1 = nn.ConvTranspose3d(48,48,kernel_size=2,stride=2)\n",
    "        y=t.cat([y,x1],dim=1)\n",
    "        y=self.layer21(y)\n",
    "        y=t.cat([y,x0],dim=1)\n",
    "        y=self.layer20(y)\n",
    "        y=self.transposeConv3(y)\n",
    "        y=t.cat([y,x],dim=1)\n",
    "        y=self.layer10(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "\n",
    "\n",
    "class NetCore(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder_part1 = Decoder_part1()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x,x0,x1,x2,x3=self.encoder(x)\n",
    "        y=self.decoder_part1(x,x0,x1,x2,x3)\n",
    "        return y\n",
    "\n",
    "\n",
    "class UNetMDModel(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = NetCore()\n",
    "        self.finalConv = nn.Sequential(\n",
    "            nn.Conv3d(16,8,1),\n",
    "            nn.Softmax(dim=1),\n",
    "        ).cuda()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        y=self.core(x)\n",
    "        y=self.finalConv(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e1ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet Model with single down sampling\n",
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,kernelSize=3):\n",
    "        super().__init__()\n",
    "        self.resnetblock1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "        self.resnetblock2 = nn.Sequential(\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.resnetblock1(x)\n",
    "        x=self.resnetblock2(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.downConv  = nn.Sequential(\n",
    "            nn.Conv3d(1,32,kernel_size=3,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "        self.layer21 = nn.Sequential(\n",
    "            ConvBlock(32,40),\n",
    "            ConvBlock(40,40)\n",
    "        )\n",
    "\n",
    "        self.layer22 = nn.Sequential(\n",
    "            ConvBlock(40,48),\n",
    "            ConvBlock(48,48)\n",
    "        )\n",
    "\n",
    "        self.layer23 = ConvBlock(48,56)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x0=self.downConv(x)\n",
    "        x1=self.layer21(x0)\n",
    "        x2=self.layer22(x1)\n",
    "        x3=self.layer23(x2)\n",
    "        return x,x0,x1,x2,x3\n",
    "\n",
    "\n",
    "class Decoder_part1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer23 = nn.Sequential(\n",
    "            ConvBlock(56,56),\n",
    "            ConvBlock(56,48)\n",
    "        )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            ConvBlock(96,48),\n",
    "            ConvBlock(48,48),\n",
    "            ConvBlock(48,40)\n",
    "        )\n",
    "        self.layer21 = nn.Sequential(\n",
    "            ConvBlock(80,40),\n",
    "            ConvBlock(40,40),\n",
    "            ConvBlock(40,32)\n",
    "        )\n",
    "        self.layer20 = nn.Sequential(\n",
    "            ConvBlock(64,32),\n",
    "            ConvBlock(32,32)\n",
    "        )\n",
    "        self.transposeConv = nn.ConvTranspose3d(32,16,kernel_size=2,stride=2)\n",
    "        self.layer10 = nn.Conv3d(17,16,kernel_size=3,padding=1)\n",
    "\n",
    "    def forward(self,x,x0,x1,x2,x3):\n",
    "        \n",
    "        y=self.layer23(x3)\n",
    "        y=t.cat([y,x2],dim=1)\n",
    "        y=self.layer22(y)\n",
    "        y=t.cat([y,x1],dim=1)\n",
    "        y=self.layer21(y)\n",
    "        y=t.cat([y,x0],dim=1)\n",
    "        y=self.layer20(y)\n",
    "        y=self.transposeConv(y)\n",
    "        y=t.cat([y,x],dim=1)\n",
    "        y=self.layer10(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "\n",
    "\n",
    "class NetCore(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder_part1 = Decoder_part1()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x,x0,x1,x2,x3=self.encoder(x)\n",
    "        y=self.decoder_part1(x,x0,x1,x2,x3)\n",
    "        return y\n",
    "\n",
    "\n",
    "class UNetModel(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = NetCore()\n",
    "        self.finalConv = nn.Sequential(\n",
    "            nn.Conv3d(16,8,1),\n",
    "            nn.Softmax(dim=1),\n",
    "        ).cuda()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        y=self.core(x)\n",
    "        y=self.finalConv(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cc6e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloading\n",
    "class HaN_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir=None, transform=False, alpha=1000, sigma=30, alpha_affine=0.04):\n",
    "        super().__init__()\n",
    "        self.path = root_dir\n",
    "        self.datas = t.load(self.path)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.alpha_affine = alpha_affine\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.datas[index]\n",
    "        img = data['img'].numpy().astype(np.float32)\n",
    "        \n",
    "        if not self.transform:\n",
    "            masklst = []\n",
    "            for mask in data['mask']:\n",
    "                if mask is None:\n",
    "                    mask = np.zeros((1,img.shape[0],img.shape[1],img.shape[2])).astype(np.uint8)\n",
    "                masklst.append(mask.astype(np.uint8).reshape((1,img.shape[0],img.shape[1],img.shape[2]))) \n",
    "            mask0 = np.zeros_like(masklst[0]).astype(np.uint8)\n",
    "            for mask in masklst:\n",
    "                mask0 = np.logical_or(mask0, mask).astype(np.uint8)\n",
    "            mask0 = 1 - mask0\n",
    "            return t.from_numpy(img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))), t.from_numpy(np.concatenate([mask0]+masklst, axis=0)), True\n",
    "        \n",
    "        im_merge = np.concatenate([img[...,None]]+[mask.astype(np.float32)[...,None] for mask in data['mask']], axis=3)\n",
    "        # Apply transformation on image\n",
    "        im_merge_t, new_img = self.elastic_transform3Dv2(im_merge,self.alpha,self.sigma,min(im_merge.shape[1:-1])*self.alpha_affine)\n",
    "        # Split image and mask ::2, ::2, ::2\n",
    "        im_t = im_merge_t[...,0]\n",
    "        im_mask_t = im_merge_t[..., 1:].astype(np.uint8).transpose(3, 0, 1, 2)\n",
    "        mask0 = np.zeros_like(im_mask_t[0, :, :, :]).reshape((1,)+im_mask_t.shape[1:]).astype(np.uint8)\n",
    "        im_mask_t_lst = []\n",
    "        flagvect = np.ones((8,), np.float32)\n",
    "        retflag = True\n",
    "        for i in range(7):\n",
    "            im_mask_t_lst.append(im_mask_t[i,:,:,:].reshape((1,)+im_mask_t.shape[1:]))\n",
    "            if im_mask_t[i,:,:,:].max() != 1: \n",
    "                retflag = False\n",
    "                flagvect[i+1] = 0\n",
    "            mask0 = np.logical_or(mask0, im_mask_t[i,:,:,:]).astype(np.uint8)\n",
    "        if not retflag: flagvect[0] = 0\n",
    "        mask0 = 1 - mask0\n",
    "        return t.from_numpy(im_t.reshape((1,)+im_t.shape[:3])), t.from_numpy(np.concatenate([mask0]+im_mask_t_lst, axis=0)), flagvect\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def elastic_transform3Dv2(self, image, alpha, sigma, alpha_affine, random_state=None):\n",
    "        \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
    "        .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "             Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "             Proc. of the International Conference on Document Analysis and\n",
    "             Recognition, 2003.\n",
    "         Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "         From https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation\n",
    "        \"\"\"\n",
    "        # affine and deformation must be slice by slice and fixed for slices\n",
    "        if random_state is None:\n",
    "            random_state = np.random.RandomState(None)\n",
    "        shape = image.shape # image is contatenated, the first channel [:,:,:,0] is the image, the second channel \n",
    "        # [:,:,:,1] is the mask. The two channel are under the same tranformation.\n",
    "        shape_size = shape[:-1] # z y x\n",
    "        # Random affine\n",
    "        shape_size_aff = shape[1:-1] # y x\n",
    "        center_square = np.float32(shape_size_aff) // 2\n",
    "        square_size = min(shape_size_aff) // 3\n",
    "        pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "        pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        new_img = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img[i,:,:,0] = cv2.warpAffine(image[i,:,:,0], M, shape_size_aff[::-1], borderMode=cv2.BORDER_CONSTANT, borderValue=0.)\n",
    "            for j in range(1, 8):\n",
    "                new_img[i,:,:,j] = cv2.warpAffine(image[i,:,:,j], M, shape_size_aff[::-1], flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_TRANSPARENT, borderValue=0)\n",
    "        dx = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        x, y = np.meshgrid(np.arange(shape_size_aff[1]), np.arange(shape_size_aff[0]))\n",
    "        indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "        new_img2 = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img2[i,:,:,0] = map_coordinates(new_img[i,:,:,0], indices, order=1, mode='constant').reshape(shape[1:-1])\n",
    "            for j in range(1, 8):\n",
    "                new_img2[i,:,:,j] = map_coordinates(new_img[i,:,:,j], indices, order=0, mode='constant').reshape(shape[1:-1])\n",
    "        return np.array(new_img2), new_img\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac416e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "traindataset = HaN_Dataset(train_path, transform=True)\n",
    "traindataloader = DataLoader(traindataset, batch_size=1, shuffle=True)\n",
    "testdataset = HaN_Dataset(test_path, transform=False)\n",
    "testdataloader = DataLoader(testdataset, batch_size=1)\n",
    "\n",
    "print(len(traindataloader),len(testdataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39efb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def crossentropy(y_pred, y_true, flagvec, device):\n",
    "    retv = - t.sum(t.sum(t.sum(t.sum(t.log(t.clamp(y_pred,1e-6,1))*y_true.type(t.cuda.FloatTensor),4),3),2),0) * flagvec.to(device)\n",
    "    return t.sum(retv / (t.sum(t.sum(t.sum(t.sum(y_true.type(t.cuda.FloatTensor),4),3),2),0) + 1e-6)) / y_true.size()[1]\n",
    "# %%\n",
    "\n",
    "def tversky_loss_wmask(y_pred, y_true, flagvec, device):\n",
    "    alpha = 0.5\n",
    "    beta  = 0.5\n",
    "    ones = t.ones_like(y_pred) \n",
    "\n",
    "    p0 = y_pred      # proba that voxels are class i\n",
    "    p1 = ones-y_pred # proba that voxels are not class i\n",
    "    g0 = y_true.type(t.cuda.FloatTensor)\n",
    "    g1 = ones-g0\n",
    "    num = t.sum(t.sum(t.sum(t.sum(p0*g0, 4),3),2),0) #(0,2,3,4)) #K.sum(p0*g0, (0,1,2,3))\n",
    "    den = num + alpha*t.sum(t.sum(t.sum(t.sum(p0*g1,4),3),2),0) + beta*t.sum(t.sum(t.sum(t.sum(p1*g0,4),3),2),0) #(0,2,3,4))\n",
    "\n",
    "    T = t.sum((num* flagvec.to(device))/(den+1e-5))\n",
    "    return t.sum(flagvec.to(device))-T\n",
    "# %%\n",
    "\n",
    "def focal(y_pred, y_true, flagvec, device):\n",
    "    retv = - t.mean(t.mean(t.mean(t.mean(t.log(t.clamp(y_pred,1e-6,1))*y_true.type(t.cuda.FloatTensor)*t.pow(1-y_pred,2),4),3),2),0) * flagvec.to(device)\n",
    "    return t.sum(retv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d505e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSC evaluation\n",
    "def caldice(y_pred, y_true):\n",
    "\n",
    "    y_pred = y_pred.data.cpu().numpy().transpose(1,0,2,3,4) # inference should be arg max\n",
    "    y_pred = np.argmax(y_pred, axis=0).squeeze() # z y x\n",
    "    y_true = y_true.data.cpu().numpy().transpose(1,0,2,3,4).squeeze() # .cpu()\n",
    "    avgdice = []\n",
    "    y_pred_1 = y_pred==1\n",
    "    y_true_1 = y_true[1,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==2\n",
    "    y_true_1 = y_true[2,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==3\n",
    "    y_true_1 = y_true[3,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==4\n",
    "    y_true_1 = y_true[4,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==5\n",
    "    y_true_1 = y_true[5,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==6\n",
    "    y_true_1 = y_true[6,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==7\n",
    "    y_true_1 = y_true[7,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "\n",
    "    for dice in avgdice: \n",
    "        if dice != -1:\n",
    "            assert 0 <= dice <= 1\n",
    "    return avgdice\n",
    "\n",
    "def get_yPredDash(y_pred):\n",
    "    \n",
    "    y_pred = y_pred.data.cpu().numpy() # inference should be arg max\n",
    "    y_pred_1 = np.zeros_like(y_pred).astype(np.uint8)\n",
    "    y_pred = np.argmax(y_pred, axis=1).squeeze() # z y x\n",
    "    \n",
    "    for i in range(8):\n",
    "        y_pred_1[:,i,:,:,:] = y_pred==i\n",
    "    \n",
    "    return y_pred_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe10cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  7.445462689877342 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.000000: 100%|██████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 10.91513987928629\n",
      "epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:55<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  6.853249417934059 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.001681: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 14.419372868537902\n",
      "epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:56<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  6.632075938635332 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.099441: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 9.713237255066634\n",
      "epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  5.885906265169988 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.319252: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.133448979258537\n",
      "epoch  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  5.035206227720703 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.088104: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 10.293492108210922\n",
      "epoch  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  4.32560690460242 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.490200: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 5.671873817592859\n",
      "epoch  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:00<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.873330064581156 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.282791: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.134862709790468\n",
      "epoch  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.545882384506715 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.540340: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 5.191286789625883\n",
      "epoch  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.4986105566398544 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.580258: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.729709285870195\n",
      "epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.1346747113062237 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.295366: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 7.262586679495871\n",
      "epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.0849429209960344 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.054358: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 10.083782557025552\n",
      "epoch  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.9050396068364557 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.646598: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.054118735343218\n",
      "epoch  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.867635325800961 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.494137: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 5.012830246053636\n",
      "epoch  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.6568679287406214 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.482597: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 5.366959282197058\n",
      "epoch  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.3951189016391714 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.665410: 100%|██████████████████████| 20/20 [00:11<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.5872293427586555\n",
      "epoch  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:59<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.3930786406832443 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.202351: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 7.965174484439194\n",
      "epoch  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:59<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.548286971169214 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.675442: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.9133665373548867\n",
      "epoch  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:56<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.3823601432063675 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.059522: 100%|██████████████████████| 20/20 [00:11<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 9.686972279287875\n",
      "epoch  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.1940667642464184 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.628116: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.816734076291323\n",
      "epoch  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.244363601167697 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.748577: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.1083775193430485\n",
      "epoch  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.198741868999428 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.740893: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.0919954787939785\n",
      "epoch  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:56<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.153107406328677 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.728346: 100%|██████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.963100687135011\n",
      "epoch  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.1358258020996517 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.221998: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 10.463071128726005\n",
      "epoch  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.1651194147261217 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.705274: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.012286640983075\n",
      "epoch  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.0062420366733873 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.745771: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.7670116084162144\n",
      "epoch  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:59<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.0519600721133786 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.674316: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.287797141261399\n",
      "epoch  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.928975377288975 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.737058: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.809422331210226\n",
      "epoch  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:59<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9419415212578142 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.720685: 100%|██████████████████████| 20/20 [00:12<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.056254081334919\n",
      "epoch  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:59<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9106256728477378 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.660150: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.3744080936536194\n",
      "epoch  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9772274996312909 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.761889: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.647910965420306\n",
      "epoch  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8724330380452483 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.571500: 100%|██████████████████████| 20/20 [00:11<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.636556627508253\n",
      "epoch  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:57<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.846412961361174 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.775601: 100%|██████████████████████| 20/20 [00:11<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.496028181351721\n",
      "epoch  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:59<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9056940480376832 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.705595: 100%|██████████████████████| 20/20 [00:11<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.25148964272812\n",
      "epoch  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:00<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.841412505636533 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.616006: 100%|██████████████████████| 20/20 [00:11<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.01994109954685\n",
      "epoch  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:58<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8827418317682865 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.526770: 100%|██████████████████████| 20/20 [00:11<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.706795179843903\n",
      "epoch  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:56<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8911436876473546 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.059647: 100%|██████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 9.633980687707663\n",
      "epoch  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [09:56<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.855086611940937 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.645033: 100%|██████████████████████| 20/20 [00:11<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.677508589532226\n",
      "epoch  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7777885000633298 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.294730: 100%|██████████████████████| 20/20 [00:11<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 7.902829267270863\n",
      "epoch  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:45<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8356557849110342 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.705413: 100%|██████████████████████| 20/20 [00:11<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.051228265091777\n",
      "epoch  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:14<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7592857967717606 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.753114: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.6370276494883003\n",
      "epoch  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:32<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7322160163028768 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.791998: 100%|██████████████████████| 20/20 [00:12<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.4660373232793065\n",
      "epoch  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:27<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7376632210601317 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.758350: 100%|██████████████████████| 20/20 [00:12<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.586537541728467\n",
      "epoch  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:26<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.6625213050067282 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.787169: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.3667343916371464\n",
      "epoch  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:21<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7383100913511478 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.747504: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.7407277286984026\n",
      "epoch  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:28<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7173222339006833 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.432493: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 5.9495643872767685\n",
      "epoch  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████▋        | 168/211 [08:15<02:06,  2.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2193/977201038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2193/904308984.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mim_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Apply transformation on image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mim_merge_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melastic_transform3Dv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_merge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_merge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_affine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Split image and mask ::2, ::2, ::2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mim_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_merge_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2193/904308984.py\u001b[0m in \u001b[0;36melastic_transform3Dv2\u001b[0;34m(self, image, alpha, sigma, alpha_affine, random_state)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mnew_img2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnew_img2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36mmap_coordinates\u001b[0;34m(input, coordinates, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m     _nd_image.geometric_transform(filtered, None, coordinates, None, None,\n\u001b[0m\u001b[1;32m    457\u001b[0m                                   output, order, mode, cval, npad, None, None)\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Unet  training\n",
    "epoch1=50\n",
    "\n",
    "UNet_Model = UNetModel()\n",
    "model=UNet_Model.to(device)\n",
    "\n",
    "lossweight = np.array([2.22, 1.06, 1.02, 1.74, 1.93, 1.93, 1.13, 1.15], np.float32)\n",
    "ceweight = 0.05\n",
    "focweight = 0.5\n",
    "\n",
    "optimizer = t.optim.RMSprop(model.parameters(),lr = 2e-3)\n",
    "\n",
    "#for epoch in range(anatomy_epoch1):\n",
    "for epoch in range(epoch1):\n",
    "    i=0\n",
    "    j=0\n",
    "    train_loss = 0\n",
    "    print(\"epoch \", epoch+1)\n",
    "    for x_train, y_train, flagvec in tqdm.tqdm(traindataloader):\n",
    "        \n",
    "        i+=1\n",
    "        model.train()\n",
    "        #print(f'epoch {epoch+1} batch {i} tensor_shape {x_train.shape}')\n",
    "        if x_train.shape[-2] > 300:\n",
    "            x_train = x_train[...,10:,:]\n",
    "            y_train = y_train[...,10:,:]\n",
    "        \n",
    "        x_train = x_train.to(device1)\n",
    "        out =model(x_train)\n",
    "        \n",
    "        out = out.to(device2)\n",
    "        y_train = y_train.to(device2)\n",
    "        loss = tversky_loss_wmask(out, y_train, flagvec*t.from_numpy(lossweight), device2)\n",
    "        celoss = crossentropy(out, y_train, flagvec*t.from_numpy(lossweight), device2)\n",
    "        floss = focal(out, y_train, flagvec*t.from_numpy(lossweight), device2)\n",
    "        optimizer.zero_grad()\n",
    "        (loss + (ceweight*celoss) + (focweight*floss)).backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() + (ceweight*celoss).item() + (focweight*floss).item()\n",
    "\n",
    "        y_train.detach_()\n",
    "        out.detach_()\n",
    "        del loss, x_train, y_train, out, floss, celoss\n",
    "        \n",
    "    print(\"train loss: \",train_loss/(len(traindataloader)-j),'\\n')\n",
    "    \n",
    "    testtq = tqdm.tqdm(testdataloader)#, desc='loss', leave=True)\n",
    "    test_loss = 0\n",
    "    testloss = [0 for _ in range(7)]\n",
    "    for x_test, y_test, flagvecTest in testtq:\n",
    "        with t.no_grad():\n",
    "            model.eval()\n",
    "            x_test = x_test.to(device1)\n",
    "            y_test = y_test.to(device2)\n",
    "            out = model(x_test)\n",
    "            out = out.to(device2)\n",
    "            loss = tversky_loss_wmask(out, y_test, flagvecTest*t.from_numpy(lossweight), device2)\n",
    "            celoss = crossentropy(out, y_test, flagvecTest*t.from_numpy(lossweight), device2)\n",
    "            floss = focal(out, y_test, flagvecTest*t.from_numpy(lossweight), device2)\n",
    "            test_loss += loss.item() + (ceweight*celoss).item() + (focweight*floss).item()\n",
    "            dice= caldice(out, y_test)\n",
    "            testtq.set_description(\"dice value %f\" % (sum(dice)/7))\n",
    "            testtq.refresh()\n",
    "            testloss = [l+tl if l != -1 else tl for l,tl in zip(dice, testloss)]\n",
    "            del out, x_test, y_test\n",
    "            \n",
    "    print(f\"test loss: {test_loss/len(testdataloader)}\")\n",
    "    \n",
    "    with open(file_name_1, \"a\") as f:\n",
    "        f.write(f\"epoch {epoch+1}\")\n",
    "        f.write(f\"\\ttrain loss: {train_loss/(len(traindataloader)-j)}\")\n",
    "        f.write(f\"\\ttest loss: {test_loss/len(testdataloader)}\\n\")\n",
    "                           \n",
    "    testloss = [l / len(testtq) for l in testloss]\n",
    "    with open(file_name_2, \"a\") as f:\n",
    "        f.write(f\"epoch {epoch+1}\")\n",
    "        f.write('\\tDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "            \n",
    "    if (epoch+1)%10==0:\n",
    "        \n",
    "        t.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict':  model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, epoch150_path_name)\n",
    "        \n",
    "        with open(file_name, \"a\") as f:\n",
    "            f.write(f\"epoch {epoch+1}\")\n",
    "            f.write('\\tDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "        \n",
    "        for x,y,_ in testdataloader:\n",
    "            with t.no_grad():\n",
    "                y_pred = model(x.to(device1))\n",
    "                y_predDash = get_yPredDash(y_pred)\n",
    "                np.save(y_pred_path,y_predDash)\n",
    "                np.save(y_true_path,y.cpu())\n",
    "                #print(y_pred.shape, y.shape) \n",
    "                break\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f159043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#evaluation Step1\n",
    "weight_path= \"Weights/Unet_tcia_40.pth\"\n",
    "UNet_Model = UNetModel()\n",
    "loaded_model = t.load(weight_path, map_location='cuda:0')\n",
    "print(loaded_model[\"epoch\"])\n",
    "UNet_Model.load_state_dict(loaded_model[\"model_state_dict\"])\n",
    "model=UNet_Model.to(device)\n",
    "\n",
    "testdataset = HaN_Dataset(test_path, transform=False)\n",
    "testdataloader = DataLoader(testdataset, batch_size=1)\n",
    "\n",
    "print(len(testdataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09a96eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.753114: 100%|███████████████████████| 20/20 [00:12<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDice coeff 0.7032, 0.5786, 0.8748, 0.7081, 0.7328, 0.7996, 0.8208 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluation Step2\n",
    "testloss = [0 for _ in range(7)]\n",
    "testtq = tqdm.tqdm(testdataloader, desc='loss', leave=True)\n",
    "\n",
    "for x_test, y_test, _ in testtq:\n",
    "    with t.no_grad():\n",
    "        model.eval()\n",
    "        x_test = x_test.to(device1) #(device1)\n",
    "        y_test = y_test.to(device2) #(device2)\n",
    "        o = model(x_test)\n",
    "        o = o.to(device2) #(device2)\n",
    "        loss = caldice(o, y_test)\n",
    "        testtq.set_description(\"test loss %f\" % (sum(loss)/7))\n",
    "        testtq.refresh() # to show immediately the update\n",
    "        testloss = [l+tl if l != -1 else tl for l,tl in zip(loss, testloss)]  #testloss = [l+tl for l,tl in zip(loss, testloss)]\n",
    "        del x_test, y_test, o\n",
    "        \n",
    "testloss = [l / len(testtq) for l in testloss]\n",
    "print('\\tDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "#f.write('\\tMeanDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "#f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522bdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
