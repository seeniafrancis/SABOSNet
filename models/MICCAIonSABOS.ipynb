{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d97e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 27 05:24:01 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    68W / 275W |  13297MiB / 40536MiB |     40%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   56C    P0    87W / 275W |  26102MiB / 40536MiB |     25%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   104W / 275W |  37478MiB / 40536MiB |    100%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b2ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchio\n",
      "  Downloading torchio-0.18.71-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 700 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torchio) (4.62.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from torchio) (1.6.3)\n",
      "Collecting SimpleITK!=2.0.*\n",
      "  Downloading SimpleITK-2.1.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.4 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from torchio) (8.0.3)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from torchio) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.8/site-packages (from torchio) (1.11.0a0+b6df043)\n",
      "Collecting humanize\n",
      "  Downloading humanize-3.13.1-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 9.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting nibabel\n",
      "  Downloading nibabel-3.2.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.13.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 10.5 MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.8/site-packages (from nibabel->torchio) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=14.3->nibabel->torchio) (3.0.5)\n",
      "Installing collected packages: wrapt, SimpleITK, nibabel, humanize, Deprecated, torchio\n",
      "Successfully installed Deprecated-1.2.13 SimpleITK-2.1.1 humanize-3.13.1 nibabel-3.2.1 torchio-0.18.71 wrapt-1.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b71fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting monai\n",
      "  Downloading monai-0.8.0-202111251823-py3-none-any.whl (709 kB)\n",
      "\u001b[K     |████████████████████████████████| 709 kB 221 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from monai) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->monai) (3.10.0.2)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72155d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm\n",
    "import random\n",
    "import copy\n",
    "import torchio\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c681dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "t.backends.cudnn.enabled = True\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "#device = t.device(\"cuda:2\")\n",
    "\n",
    "device = t.device(\"cuda:2\")\n",
    "device1 = t.device(\"cuda:2\")\n",
    "device2 = t.device(\"cuda:1\")\n",
    "print (device)\n",
    "#device = \"cuda:0\"\n",
    "#device1 = \"cuda:0\"\n",
    "#device2 = \"cuda:1\"\n",
    "\n",
    "epoch150_path_name = \"MICCCAI_tcia_150.pth\"\n",
    "epoch150_50_path_name = \"MICCAI_tcia_150+50.pth\"\n",
    "\n",
    "\n",
    "file_name = \"MICCAI_dice_log_tcia.txt\"\n",
    "file_name_1 = \"MICCAI_loss_log_tcia.txt\"\n",
    "file_name_2 = \"MICCAI_totalDice_log_tcia.txt\"\n",
    "\n",
    "y_pred_path = \"OutputsTcia/MICCAI_pred_tcia\"\n",
    "y_true_path = \"OutputsTcia/MICCAI_true_tcia\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ee2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encoder - Decoder Network\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return t.cat((t.max(x,1)[0].unsqueeze(1), t.mean(x,1).unsqueeze(1)),dim=1)\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.compress = ChannelPool()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(2,1,kernel_size=7,stride=1,padding=3, bias=False),\n",
    "            nn.BatchNorm3d(1,eps=1e-5,momentum=0.01,affine=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        xcompress=self.compress(x)\n",
    "        spatialAttention=self.conv(xcompress)\n",
    "        return x*spatialAttention\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "  \n",
    "    def __init__(self,channels,reductionRatio=16,poolTypes=['avg','max']):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(channels,channels//reductionRatio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels//reductionRatio,channels)\n",
    "        )\n",
    "        self.poolTypes = poolTypes\n",
    "  \n",
    "    def forward(self,x):\n",
    "        attentionSum = None\n",
    "        for poolType in self.poolTypes:\n",
    "            if poolType=='avg':\n",
    "                avgPool = F.avg_pool3d(x,(x.size(2),x.size(3),x.size(4)),stride=(x.size(2),x.size(3),x.size(4)))\n",
    "                channelAttention = self.mlp(avgPool)\n",
    "            if poolType=='max':\n",
    "                maxPool = F.max_pool3d(x,(x.size(2),x.size(3),x.size(4)),stride=(x.size(2),x.size(3),x.size(4)))\n",
    "                channelAttention = self.mlp(maxPool)\n",
    "        if attentionSum is None:\n",
    "              attentionSum = channelAttention\n",
    "        else:\n",
    "              attentionSum=attentionSum+channelAttention\n",
    "    \n",
    "        scale=t.sigmoid(attentionSum).unsqueeze(2).unsqueeze(3).unsqueeze(4).expand_as(x)\n",
    "        return x*scale\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "  \n",
    "    def __init__(self,channels,reductionRatio=16,poolTypes=['avg','max']):\n",
    "        super().__init__()\n",
    "        self.channelGate = ChannelGate(channels,reductionRatio,poolTypes)\n",
    "        self.spatialGate = SpatialGate()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.spatialGate(x)\n",
    "        x=self.channelGate(x)\n",
    "        return x \n",
    "    \n",
    "class CBAMResnetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,kernelSize=3):\n",
    "        super().__init__()\n",
    "        self.resnetblock1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "        self.resnetblock2 = nn.Sequential(\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "        self.CBAM = CBAM(out_channels,16,['avg','max'])\n",
    "        self.reluUnit = nn.Sequential(\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.resnetblock1(x)\n",
    "        x1=x\n",
    "        x=self.resnetblock2(x)\n",
    "        x=self.CBAM(x)\n",
    "        x=x+x1\n",
    "        x=self.reluUnit(x)\n",
    "        return x\n",
    "    \n",
    "class GSEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.downConv  = nn.Sequential(\n",
    "            nn.Conv3d(1,32,kernel_size=3,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "        self.layer21 = nn.Sequential(\n",
    "            CBAMResnetBlock(32,40),\n",
    "            CBAMResnetBlock(40,40)\n",
    "        )\n",
    "\n",
    "        self.layer22 = nn.Sequential(\n",
    "            CBAMResnetBlock(40,48),\n",
    "            CBAMResnetBlock(48,48)\n",
    "        )\n",
    "\n",
    "        self.layer23 = CBAMResnetBlock(48,56)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x0=self.downConv(x)\n",
    "        x1=self.layer21(x0)\n",
    "        x2=self.layer22(x1)\n",
    "        x3=self.layer23(x2)\n",
    "        #print(x3.shape)\n",
    "        return x,x0,x1,x2,x3\n",
    "\n",
    "\n",
    "class GSDecoder_part1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer23 = nn.Sequential(\n",
    "            CBAMResnetBlock(56,56),\n",
    "            CBAMResnetBlock(56,48)\n",
    "        )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            CBAMResnetBlock(96,48),\n",
    "            CBAMResnetBlock(48,48),\n",
    "            CBAMResnetBlock(48,40)\n",
    "        )\n",
    "        self.layer21 = nn.Sequential(\n",
    "            CBAMResnetBlock(80,40),\n",
    "            CBAMResnetBlock(40,40),\n",
    "            CBAMResnetBlock(40,32)\n",
    "        )\n",
    "        self.layer20 = nn.Sequential(\n",
    "            CBAMResnetBlock(64,32),\n",
    "            CBAMResnetBlock(32,32)\n",
    "        )\n",
    "        self.transposeConv = nn.ConvTranspose3d(32,16,kernel_size=2,stride=2)\n",
    "        self.layer10 = nn.Conv3d(17,16,kernel_size=3,padding=1)\n",
    "\n",
    "    def forward(self,x,x0,x1,x2,x3):\n",
    "        \n",
    "        y=self.layer23(x3)\n",
    "        y=t.cat([y,x2],dim=1)\n",
    "        y=self.layer22(y)\n",
    "        y=t.cat([y,x1],dim=1)\n",
    "        y=self.layer21(y)\n",
    "        y=t.cat([y,x0],dim=1)\n",
    "        y=self.layer20(y)\n",
    "        y=self.transposeConv(y)\n",
    "        y=t.cat([y,x],dim=1)\n",
    "        y=self.layer10(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "\n",
    "\n",
    "class GSNetCore(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = GSEncoder() .to(device2)\n",
    "        self.decoder_part1 = GSDecoder_part1().to(device2)\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x,x0,x1,x2,x3=self.encoder(x)\n",
    "        y=self.decoder_part1(x,x0,x1,x2,x3)\n",
    "        return y\n",
    "\n",
    "\n",
    "class GSNetModel(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = GSNetCore()\n",
    "        self.finalConv = nn.Sequential(\n",
    "            nn.Conv3d(16,8,1),\n",
    "            nn.Softmax(dim=1),\n",
    "        ).cuda()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        y=self.core(x)\n",
    "        y=self.finalConv(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e44ef3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaN_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir=None, transform=False, alpha=1000, sigma=30, alpha_affine=0.04):\n",
    "        super().__init__()\n",
    "        self.path = root_dir\n",
    "        self.datas = t.load(self.path)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.alpha_affine = alpha_affine\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.datas[index]\n",
    "        img = data['img'].numpy().astype(np.float32)\n",
    "        \n",
    "        if not self.transform:\n",
    "            masklst = []\n",
    "            for mask in data['mask']:\n",
    "                if mask is None:\n",
    "                    mask = np.zeros((1,img.shape[0],img.shape[1],img.shape[2])).astype(np.uint8)\n",
    "                masklst.append(mask.astype(np.uint8).reshape((1,img.shape[0],img.shape[1],img.shape[2]))) \n",
    "            mask0 = np.zeros_like(masklst[0]).astype(np.uint8)\n",
    "            for mask in masklst:\n",
    "                mask0 = np.logical_or(mask0, mask).astype(np.uint8)\n",
    "            mask0 = 1 - mask0\n",
    "            return t.from_numpy(img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))), t.from_numpy(np.concatenate([mask0]+masklst[0:7], axis=0)), True\n",
    "        \n",
    "       \n",
    "        im_merge = np.concatenate([img[...,None]]+[mask.astype(np.float32)[...,None] for mask in data['mask']], axis=3)\n",
    "        # Apply transformation on image\n",
    "        im_merge_t, new_img = self.elastic_transform3Dv2(im_merge,self.alpha,self.sigma,min(im_merge.shape[1:-1])*self.alpha_affine)\n",
    "        # Split image and mask ::2, ::2, ::2\n",
    "        im_t = im_merge_t[...,0]\n",
    "        im_mask_t = im_merge_t[..., 1:].astype(np.uint8).transpose(3, 0, 1, 2)\n",
    "        mask0 = np.zeros_like(im_mask_t[0, :, :, :]).reshape((1,)+im_mask_t.shape[1:]).astype(np.uint8)\n",
    "        im_mask_t_lst = []\n",
    "        flagvect = np.ones((8,), np.float32)\n",
    "        retflag = True\n",
    "        for i in range(7):\n",
    "            im_mask_t_lst.append(im_mask_t[i,:,:,:].reshape((1,)+im_mask_t.shape[1:]))\n",
    "            if im_mask_t[i,:,:,:].max() != 1: \n",
    "                retflag = False\n",
    "                flagvect[i+1] = 0\n",
    "            mask0 = np.logical_or(mask0, im_mask_t[i,:,:,:]).astype(np.uint8)\n",
    "        if not retflag: flagvect[0] = 0\n",
    "        mask0 = 1 - mask0\n",
    "        return t.from_numpy(im_t.reshape((1,)+im_t.shape[:3])), t.from_numpy(np.concatenate([mask0]+im_mask_t_lst, axis=0)), flagvect\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def elastic_transform3Dv2(self, image, alpha, sigma, alpha_affine, random_state=None):\n",
    "        \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
    "        .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "             Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "             Proc. of the International Conference on Document Analysis and\n",
    "             Recognition, 2003.\n",
    "         Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "         From https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation\n",
    "        \"\"\"\n",
    "        # affine and deformation must be slice by slice and fixed for slices\n",
    "        if random_state is None:\n",
    "            random_state = np.random.RandomState(None)\n",
    "        shape = image.shape # image is contatenated, the first channel [:,:,:,0] is the image, the second channel \n",
    "        # [:,:,:,1] is the mask. The two channel are under the same tranformation.\n",
    "        shape_size = shape[:-1] # z y x\n",
    "        # Random affine\n",
    "        shape_size_aff = shape[1:-1] # y x\n",
    "        center_square = np.float32(shape_size_aff) // 2\n",
    "        square_size = min(shape_size_aff) // 3\n",
    "        pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "        pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        new_img = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img[i,:,:,0] = cv2.warpAffine(image[i,:,:,0], M, shape_size_aff[::-1], borderMode=cv2.BORDER_CONSTANT, borderValue=0.)\n",
    "            for j in range(1, 8):\n",
    "                new_img[i,:,:,j] = cv2.warpAffine(image[i,:,:,j], M, shape_size_aff[::-1], flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_TRANSPARENT, borderValue=0)\n",
    "        dx = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        x, y = np.meshgrid(np.arange(shape_size_aff[1]), np.arange(shape_size_aff[0]))\n",
    "        indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "        new_img2 = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img2[i,:,:,0] = map_coordinates(new_img[i,:,:,0], indices, order=1, mode='constant').reshape(shape[1:-1])\n",
    "            for j in range(1, 8):\n",
    "                new_img2[i,:,:,j] = map_coordinates(new_img[i,:,:,j], indices, order=0, mode='constant').reshape(shape[1:-1])\n",
    "        return np.array(new_img2), new_img\n",
    "      \n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a71baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 38\n"
     ]
    }
   ],
   "source": [
    "#loading MiCCAi data\n",
    "traindataset = HaN_Dataset(\"Data/train_data38.pth\", transform=True)\n",
    "traindataloader = DataLoader(traindataset, batch_size=1, shuffle=True)\n",
    "testdataset = HaN_Dataset(\"Data/test_data.pth\", transform=False)\n",
    "testdataloader = DataLoader(testdataset, batch_size=1)\n",
    "\n",
    "print(len(testdataloader), len(traindataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf18009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(y_pred, y_true, flagvec, device):\n",
    "    retv = - t.sum(t.sum(t.sum(t.sum(t.log(t.clamp(y_pred,1e-6,1))*y_true.type(t.cuda.FloatTensor),4),3),2),0) * flagvec.to(device)\n",
    "    return t.sum(retv / (t.sum(t.sum(t.sum(t.sum(y_true.type(t.cuda.FloatTensor),4),3),2),0) + 1e-6)) / y_true.size()[1]\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "def tversky_loss_wmask(y_pred, y_true, flagvec, device):\n",
    "    alpha = 0.5\n",
    "    beta  = 0.5\n",
    "    ones = t.ones_like(y_pred) \n",
    "\n",
    "    p0 = y_pred      # proba that voxels are class i\n",
    "    p1 = ones-y_pred # proba that voxels are not class i\n",
    "    g0 = y_true.type(t.cuda.FloatTensor)\n",
    "    g1 = ones-g0\n",
    "    num = t.sum(t.sum(t.sum(t.sum(p0*g0, 4),3),2),0) #(0,2,3,4)) #K.sum(p0*g0, (0,1,2,3))\n",
    "    den = num + alpha*t.sum(t.sum(t.sum(t.sum(p0*g1,4),3),2),0) + beta*t.sum(t.sum(t.sum(t.sum(p1*g0,4),3),2),0) #(0,2,3,4))\n",
    "\n",
    "    T = t.sum((num* flagvec.to(device))/(den+1e-5))\n",
    "    return t.sum(flagvec.to(device))-T\n",
    "\n",
    "# %%\n",
    "\n",
    "def focal(y_pred, y_true, flagvec, device):\n",
    "    retv = - t.mean(t.mean(t.mean(t.mean(t.log(t.clamp(y_pred,1e-6,1))*y_true.type(t.cuda.FloatTensor)*t.pow(1-y_pred,2),4),3),2),0) * flagvec.to(device)\n",
    "    return t.sum(retv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8457d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caldice(y_pred, y_true):\n",
    "\n",
    "    y_pred = y_pred.data.cpu().numpy().transpose(1,0,2,3,4) # inference should be arg max\n",
    "    y_pred = np.argmax(y_pred, axis=0).squeeze() # z y x\n",
    "    y_true = y_true.data.cpu().numpy().transpose(1,0,2,3,4).squeeze() # .cpu()\n",
    "    avgdice = []\n",
    "    y_pred_1 = y_pred==1\n",
    "    y_true_1 = y_true[1,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==2\n",
    "    y_true_1 = y_true[2,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==3\n",
    "    y_true_1 = y_true[3,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==4\n",
    "    y_true_1 = y_true[4,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==5\n",
    "    y_true_1 = y_true[5,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==6\n",
    "    y_true_1 = y_true[6,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==7\n",
    "    y_true_1 = y_true[7,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "\n",
    "    for dice in avgdice: \n",
    "        if dice != -1:\n",
    "            assert 0 <= dice <= 1\n",
    "    return avgdice\n",
    "\n",
    "def get_yPredDash(y_pred):\n",
    "    \n",
    "    y_pred = y_pred.data.cpu().numpy() # inference should be arg max\n",
    "    y_pred_1 = np.zeros_like(y_pred).astype(np.uint8)\n",
    "    y_pred = np.argmax(y_pred, axis=1).squeeze() # z y x\n",
    "    \n",
    "    for i in range(8):\n",
    "        y_pred_1[:,i,:,:,:] = y_pred==i\n",
    "    \n",
    "    return y_pred_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3eff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded\n"
     ]
    }
   ],
   "source": [
    "#loading the network with trained weights\n",
    "import time\n",
    "SSABAM_Model = GSNetModel().cuda()\n",
    "SSABAM_Model.to(device)\n",
    "\n",
    "loaded_model = t.load(\"Weights/swap10_tcia_120+80.pth\", map_location='cuda:0')\n",
    "SSABAM_Model.load_state_dict(loaded_model[\"model_state_dict\"])\n",
    "print(\"Weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977df9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:38<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.876459518790637 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.704241: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8395, 0.3492, 0.9213, 0.6059, 0.6110, 0.8647, 0.8683\n",
      "best dice loss 0.8395, 0.3492, 0.9213, 0.6059, 0.6110, 0.8647, 0.8683\n",
      "epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:37<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.931033230435691 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.774116: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8453, 0.5013, 0.9319, 0.6860, 0.6630, 0.8740, 0.8677\n",
      "best dice loss 0.8453, 0.5013, 0.9319, 0.6860, 0.6630, 0.8740, 0.8683\n",
      "epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.6583441084520403 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.773428: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8460, 0.5289, 0.9252, 0.6794, 0.6825, 0.8736, 0.8765\n",
      "best dice loss 0.8460, 0.5289, 0.9319, 0.6860, 0.6825, 0.8740, 0.8765\n",
      "epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.636395290285643 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.775513: 100%|███████████████████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8496, 0.5390, 0.9338, 0.6904, 0.6888, 0.8799, 0.8798\n",
      "best dice loss 0.8496, 0.5390, 0.9338, 0.6904, 0.6888, 0.8799, 0.8798\n",
      "epoch  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.4016485637556273 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.754487: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8448, 0.4317, 0.9322, 0.6906, 0.6836, 0.8795, 0.8788\n",
      "best dice loss 0.8496, 0.5390, 0.9338, 0.6906, 0.6888, 0.8799, 0.8798\n",
      "epoch  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.340707782717226 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.772103: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8418, 0.5233, 0.9232, 0.6887, 0.6770, 0.8794, 0.8721\n",
      "best dice loss 0.8496, 0.5390, 0.9338, 0.6906, 0.6888, 0.8799, 0.8798\n",
      "epoch  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.178800947572056 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.782367: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8590, 0.4651, 0.9366, 0.6969, 0.7132, 0.8760, 0.8757\n",
      "best dice loss 0.8590, 0.5390, 0.9366, 0.6969, 0.7132, 0.8799, 0.8798\n",
      "epoch  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.141659948098669 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.796542: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8487, 0.5582, 0.9222, 0.7160, 0.6878, 0.8786, 0.8774\n",
      "best dice loss 0.8590, 0.5582, 0.9366, 0.7160, 0.7132, 0.8799, 0.8798\n",
      "epoch  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.116979842049707 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.758370: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8500, 0.5299, 0.9332, 0.6823, 0.6963, 0.8714, 0.8704\n",
      "best dice loss 0.8590, 0.5582, 0.9366, 0.7160, 0.7132, 0.8799, 0.8798\n",
      "epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.0944457400320586 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.794464: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8560, 0.5567, 0.9334, 0.6993, 0.7108, 0.8782, 0.8772\n",
      "best dice loss 0.8590, 0.5582, 0.9366, 0.7160, 0.7132, 0.8799, 0.8798\n",
      "epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.0000291598231628 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.795478: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8598, 0.5903, 0.9199, 0.6940, 0.6887, 0.8774, 0.8734\n",
      "best dice loss 0.8598, 0.5903, 0.9366, 0.7160, 0.7132, 0.8799, 0.8798\n",
      "epoch  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9302578157144843 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.798353: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8614, 0.5316, 0.9249, 0.7253, 0.6939, 0.8772, 0.8800\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8799, 0.8800\n",
      "epoch  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9177829073037413 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.787877: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8523, 0.5460, 0.9188, 0.7020, 0.7066, 0.8744, 0.8740\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8799, 0.8800\n",
      "epoch  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:37<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9028339504239786 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.744340: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8476, 0.4785, 0.9225, 0.7111, 0.6832, 0.8763, 0.7632\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8799, 0.8800\n",
      "epoch  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9407156155763292 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.786643: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8576, 0.5566, 0.9290, 0.7190, 0.7031, 0.8747, 0.8779\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8799, 0.8800\n",
      "epoch  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9655806988440945 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.782601: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8551, 0.5253, 0.9246, 0.7171, 0.6964, 0.8767, 0.8777\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8799, 0.8800\n",
      "epoch  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8016919188605818 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.802761: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8590, 0.5560, 0.9296, 0.7091, 0.7132, 0.8805, 0.8744\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8805, 0.8800\n",
      "epoch  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.758549773002558 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.782820: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8372, 0.4994, 0.9295, 0.7029, 0.7125, 0.8809, 0.8810\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8809, 0.8810\n",
      "epoch  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7744635473752983 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.789052: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8567, 0.5493, 0.9250, 0.7244, 0.7030, 0.8829, 0.8804\n",
      "best dice loss 0.8614, 0.5903, 0.9366, 0.7253, 0.7132, 0.8829, 0.8810\n",
      "epoch  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7504232281414596 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.802165: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8600, 0.6195, 0.9280, 0.7038, 0.6895, 0.8824, 0.8810\n",
      "best dice loss 0.8614, 0.6195, 0.9366, 0.7253, 0.7132, 0.8829, 0.8810\n",
      "epoch  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8070899456016425 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.804186: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8547, 0.5987, 0.9291, 0.7068, 0.6906, 0.8831, 0.8790\n",
      "best dice loss 0.8614, 0.6195, 0.9366, 0.7253, 0.7132, 0.8831, 0.8810\n",
      "epoch  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7302966138997458 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.789981: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8241, 0.5769, 0.9360, 0.7152, 0.7109, 0.8774, 0.8770\n",
      "best dice loss 0.8614, 0.6195, 0.9366, 0.7253, 0.7132, 0.8831, 0.8810\n",
      "epoch  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8240251847432534 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.789755: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8481, 0.5912, 0.9345, 0.7100, 0.7074, 0.8733, 0.8784\n",
      "best dice loss 0.8614, 0.6195, 0.9366, 0.7253, 0.7132, 0.8831, 0.8810\n",
      "epoch  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.665258309307606 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.787138: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8561, 0.6136, 0.9303, 0.6940, 0.7161, 0.8809, 0.8790\n",
      "best dice loss 0.8614, 0.6195, 0.9366, 0.7253, 0.7161, 0.8831, 0.8810\n",
      "epoch  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.663675509993673 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.791230: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8544, 0.5562, 0.9383, 0.7050, 0.7188, 0.8778, 0.8787\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7188, 0.8831, 0.8810\n",
      "epoch  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.685779107740688 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.810436: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8581, 0.5263, 0.9249, 0.7158, 0.7155, 0.8673, 0.8762\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7188, 0.8831, 0.8810\n",
      "epoch  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7382831180799065 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.790397: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8519, 0.5079, 0.9370, 0.6991, 0.7115, 0.8809, 0.8798\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7188, 0.8831, 0.8810\n",
      "epoch  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.6846520778030696 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.805003: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8530, 0.5752, 0.9309, 0.7021, 0.6990, 0.8832, 0.8804\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7188, 0.8832, 0.8810\n",
      "epoch  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.7233830836393234 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.793426: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8563, 0.5469, 0.9314, 0.6808, 0.6926, 0.8677, 0.8526\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7188, 0.8832, 0.8810\n",
      "epoch  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:37<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.6756127206179754 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.797388: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8609, 0.5503, 0.9182, 0.7187, 0.7105, 0.8792, 0.8769\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7188, 0.8832, 0.8810\n",
      "epoch  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.6026320415916608 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.799151: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8474, 0.5925, 0.9301, 0.6872, 0.7111, 0.8806, 0.8746\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7188, 0.8832, 0.8810\n",
      "epoch  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.598563877357121 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.803591: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8584, 0.5716, 0.9343, 0.7047, 0.7225, 0.8738, 0.8778\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8832, 0.8810\n",
      "epoch  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.6632707229827677 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.796618: 100%|███████████████████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8570, 0.5226, 0.9323, 0.7035, 0.7092, 0.8799, 0.8782\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8832, 0.8810\n",
      "epoch  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.6046664115948308 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.796562: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8579, 0.5682, 0.9306, 0.7191, 0.7172, 0.8844, 0.8783\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5648103983227262 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.795040: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8610, 0.5081, 0.9223, 0.7112, 0.7084, 0.8792, 0.8773\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.6191475680159209 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.796666: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8592, 0.5643, 0.9301, 0.7214, 0.7091, 0.8819, 0.8807\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5697321767649173 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.809285: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8588, 0.5512, 0.9319, 0.7093, 0.7099, 0.8840, 0.8780\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5674323785106505 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.790160: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8610, 0.5433, 0.9327, 0.7118, 0.7160, 0.8803, 0.8787\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5265866663723595 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.770127: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8521, 0.5755, 0.9226, 0.6822, 0.6897, 0.8823, 0.8782\n",
      "best dice loss 0.8614, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5635203545282006 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.806326: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8620, 0.5029, 0.9274, 0.7233, 0.6927, 0.8829, 0.8795\n",
      "best dice loss 0.8620, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:37<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5789110915012363 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.805591: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8583, 0.5341, 0.9271, 0.7103, 0.7087, 0.8771, 0.8796\n",
      "best dice loss 0.8620, 0.6195, 0.9383, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:37<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.550351777233453 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.803682: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8569, 0.5408, 0.9396, 0.7151, 0.7143, 0.8816, 0.8797\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7253, 0.7225, 0.8844, 0.8810\n",
      "epoch  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5203778468942466 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.788842: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8334, 0.5590, 0.9321, 0.6949, 0.7120, 0.8782, 0.8815\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7253, 0.7225, 0.8844, 0.8815\n",
      "epoch  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:37<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.551662221477416 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.775516: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8556, 0.4727, 0.9308, 0.6891, 0.7050, 0.8838, 0.8800\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7253, 0.7225, 0.8844, 0.8815\n",
      "epoch  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.4610677266763032 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.803435: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8609, 0.4829, 0.9324, 0.7103, 0.7034, 0.8847, 0.8849\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7253, 0.7225, 0.8847, 0.8849\n",
      "epoch  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.4802422071102468 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.797045: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8619, 0.4904, 0.9301, 0.7264, 0.7020, 0.8787, 0.8810\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7264, 0.7225, 0.8847, 0.8849\n",
      "epoch  47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.628477024551677 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.792337: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8589, 0.4591, 0.9312, 0.7283, 0.7073, 0.8764, 0.8774\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7283, 0.7225, 0.8847, 0.8849\n",
      "epoch  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.5784115943242796 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.793571: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8609, 0.4839, 0.9345, 0.7255, 0.6980, 0.8838, 0.8807\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7283, 0.7225, 0.8847, 0.8849\n",
      "epoch  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.4623544816981608 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.780984: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8547, 0.5682, 0.9223, 0.7234, 0.7064, 0.8803, 0.8803\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7283, 0.7225, 0.8847, 0.8849\n",
      "epoch  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 38/38 [01:36<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.4884516739372262 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.805980: 100%|███████████████████████| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0\n",
      "test dice 0.8597, 0.5724, 0.9297, 0.7214, 0.7165, 0.8802, 0.8818\n",
      "best dice loss 0.8620, 0.6195, 0.9396, 0.7283, 0.7225, 0.8847, 0.8849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#training the network with MICCAI data\n",
    "\n",
    "lossweight = np.array([2.22, 1.06, 1.02, 1.74, 1.93, 1.93, 1.13, 1.15], np.float32)\n",
    "ceweight = 0.05\n",
    "focweight = 0.5\n",
    "savename = 'model/MICCAI_Train_New_'\n",
    "\n",
    "optimizer = t.optim.RMSprop(SSABAM_Model.parameters(),lr = 2e-3)\n",
    "\n",
    "# %%\n",
    "epoch1=150\n",
    "epoch2=50\n",
    "#for epoch in range(anatomy_epoch1):\n",
    "maxloss = [0 for _ in range(7)]\n",
    "for epoch in range(epoch1):\n",
    "    i=0\n",
    "    j=0\n",
    "    train_loss = 0\n",
    "    print(\"epoch \", epoch+1)\n",
    "    for x_train, y_train, flagvec in tqdm.tqdm(traindataloader):\n",
    "        #Anatomy_Model.train()\n",
    "        i+=1\n",
    "\n",
    "        #print(f'epoch {epoch+1} batch {i} tensor_shape {x_train.shape}')\n",
    "        \n",
    "        \"\"\"\n",
    "        if x_train.shape[2] > 150:\n",
    "            x_train = x_train[:,:,37:37+64,...]\n",
    "            y_train = y_train[:,:,37:37+64,...]\n",
    "        \"\"\" \n",
    "        if x_train.shape[-2] > 200:\n",
    "            x_train = x_train[...,10:,:]\n",
    "            y_train = y_train[...,10:,:]\n",
    "        \n",
    "        x_train = x_train.to(device1) #(device1)\n",
    "        out = SSABAM_Model(x_train)\n",
    "        \n",
    "        out = out.to(device2) #(device2)\n",
    "        y_train = y_train.to(device2) #(device2)\n",
    "        loss = tversky_loss_wmask(out, y_train, flagvec*t.from_numpy(lossweight),device2) # device2)\n",
    "        celoss = crossentropy(out, y_train, flagvec*t.from_numpy(lossweight), device2) # device2)\n",
    "        floss = focal(out, y_train, flagvec*t.from_numpy(lossweight), device2 )  # device2)\n",
    "        optimizer.zero_grad()\n",
    "        (loss + (ceweight*celoss) + (focweight*floss)).backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() + (ceweight*celoss).item() + (focweight*floss).item()\n",
    "\n",
    "        y_train.detach_()\n",
    "        out.detach_()\n",
    "        del loss, x_train, y_train, out, floss, celoss\n",
    "        \n",
    "    print(\"train loss: \",train_loss/(len(traindataloader)-j),'\\n')\n",
    "    \n",
    "    testtq = tqdm.tqdm(testdataloader)#, desc='loss', leave=True)\n",
    "    test_loss = 0\n",
    "    testloss = [0 for _ in range(7)]\n",
    "    for x_test, y_test, flagvecTest in testtq:\n",
    "        with t.no_grad():\n",
    "            #Anatomy_Model.eval()\n",
    "            x_test = x_test.to(device1) #(device1)\n",
    "            y_test = y_test.to(device2) #(device2)\n",
    "            out = SSABAM_Model(x_test)\n",
    "            out = out.to(device2) #(device2)\n",
    "            #loss = tversky_loss_wmask(out, y_test, flagvecTest*t.from_numpy(lossweight),device2) # device2)\n",
    "            #celoss = crossentropy(out, y_test, flagvecTest*t.from_numpy(lossweight), device2) # device2)\n",
    "            #floss = focal(out, y_test, flagvecTest*t.from_numpy(lossweight),device2) #device2)\n",
    "            #test_loss += loss.item() + (ceweight*celoss).item() + (focweight*floss).item()\n",
    "            dice = caldice(out, y_test)\n",
    "            testtq.set_description(\"test loss %f\" % (sum(dice)/7))\n",
    "            testtq.refresh() # to show immediately the update\n",
    "            testloss = [l+tl if l != -1 else tl for l,tl in zip(dice, testloss)]  #testloss = [l+tl for l,tl in zip(loss, testloss)]\n",
    "            del out, x_test, y_test\n",
    "            \n",
    "    print(f\"test loss: {test_loss/len(testdataloader)}\")\n",
    "    testloss = [l / len(testtq) for l in testloss]\n",
    "    for cls in range(7):\n",
    "        if maxloss[cls] < testloss[cls]:\n",
    "            maxloss[cls] = testloss[cls]\n",
    "            state = {\"epoch\": epoch, \"weight\": SSABAM_Model.state_dict()}\n",
    "            t.save(state, savename+str(cls+1))\n",
    "#             model.load_state_dict(t.load(savename)[\"weight\"])\n",
    "#             t.save(model, savename+str(cls+1))\n",
    "    print('test dice %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f' % tuple(testloss))\n",
    "    print('best dice loss %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f' % tuple(maxloss))\n",
    "    with open(file_name_1, \"a\") as f:\n",
    "        f.write(f\"epoch {epoch+1}\")\n",
    "        f.write(f\"\\ttrain loss: {train_loss/(len(traindataloader)-j)}\")\n",
    "        f.write(f\"\\ttest loss: {test_loss/len(testdataloader)}\\n\")\n",
    "                        \n",
    "    \n",
    "    with open(file_name_2, \"a\") as f:\n",
    "        f.write(f\"epoch {epoch+1}\")\n",
    "        f.write('\\tDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "    \n",
    "\n",
    "    if (epoch+1)%10==0:\n",
    "        \n",
    "        t.save({\n",
    "        'epoch': epoch,\n",
    "        'Miccaimodel_state_dict':  SSABAM_Model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, epoch150_path_name)\n",
    "        \n",
    "        with open(file_name, \"a\") as f:\n",
    "            f.write(f\"epoch {epoch+1}\")\n",
    "            f.write('\\tDice coeff %.4f,%.4f,%.4f %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f157f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
