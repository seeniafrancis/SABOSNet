{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c36df87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 20 05:07:56 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    83W / 275W |  31015MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    56W / 275W |  15829MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    58W / 275W |      3MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffcee957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchio\n",
      "  Downloading torchio-0.18.71-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 700 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torchio) (4.62.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from torchio) (1.6.3)\n",
      "Collecting SimpleITK!=2.0.*\n",
      "  Downloading SimpleITK-2.1.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.4 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from torchio) (8.0.3)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from torchio) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.8/site-packages (from torchio) (1.11.0a0+b6df043)\n",
      "Collecting humanize\n",
      "  Downloading humanize-3.13.1-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 9.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting nibabel\n",
      "  Downloading nibabel-3.2.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.13.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 10.5 MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.8/site-packages (from nibabel->torchio) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=14.3->nibabel->torchio) (3.0.5)\n",
      "Installing collected packages: wrapt, SimpleITK, nibabel, humanize, Deprecated, torchio\n",
      "Successfully installed Deprecated-1.2.13 SimpleITK-2.1.1 humanize-3.13.1 nibabel-3.2.1 torchio-0.18.71 wrapt-1.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74113e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting monai\n",
      "  Downloading monai-0.8.0-202111251823-py3-none-any.whl (709 kB)\n",
      "\u001b[K     |████████████████████████████████| 709 kB 221 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from monai) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->monai) (3.10.0.2)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf40ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm\n",
    "import random\n",
    "import copy\n",
    "import torchio\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b3efd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "t.backends.cudnn.enabled = True\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "#device = t.device(\"cuda:2\")\n",
    "\n",
    "device = t.device(\"cuda:0\")\n",
    "device1 = t.device(\"cuda:0\")\n",
    "device2 = t.device(\"cuda:0\")\n",
    "print (device)\n",
    "#device = \"cuda:0\"\n",
    "#device1 = \"cuda:0\"\n",
    "#device2 = \"cuda:1\"\n",
    "\n",
    "train_path = \"Data/train_data_tcia.pth\"\n",
    "test_path = \"Data/test_data_tcia.pth\"\n",
    "\n",
    "file_name = \"ResUNet_dice_log_tcia.txt\"\n",
    "file_name_1 = \"ResUNet_loss_log_tcia.txt\"\n",
    "file_name_2 = \"ResUNet_totalDice_log_tcia.txt\"\n",
    "\n",
    "epoch150_path_name = \"Weights/ResUnet_tcia_42.pth\"\n",
    "\n",
    "y_pred_path = \"OutputsTcia/ResUnetpred_tcia\"\n",
    "y_true_path = \"OutputsTcia/ResUnettrue_tcia\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd3618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResUNet\n",
    "# Encoder - Decoder Network\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,kernelSize=3):\n",
    "        super().__init__()\n",
    "        self.resnetblock1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "        self.resnetblock2 = nn.Sequential(\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "        #self.CBAM = CBAM(out_channels,16,['avg','max'])\n",
    "        self.reluUnit = nn.Sequential(\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.resnetblock1(x)\n",
    "        x1=x\n",
    "        x=self.resnetblock2(x)\n",
    "        #x=self.CBAM(x)\n",
    "        x=x+x1\n",
    "        x=self.reluUnit(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.downConv  = nn.Sequential(\n",
    "            nn.Conv3d(1,32,kernel_size=3,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "        self.layer21 = nn.Sequential(\n",
    "            ResnetBlock(32,40),\n",
    "            ResnetBlock(40,40)\n",
    "        )\n",
    "\n",
    "        self.layer22 = nn.Sequential(\n",
    "            ResnetBlock(40,48),\n",
    "            ResnetBlock(48,48)\n",
    "        )\n",
    "\n",
    "        self.layer23 = ResnetBlock(48,56)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x0=self.downConv(x)\n",
    "        x1=self.layer21(x0)\n",
    "        x2=self.layer22(x1)\n",
    "        x3=self.layer23(x2)\n",
    "        #print(x3.shape)\n",
    "        return x,x0,x1,x2,x3\n",
    "\n",
    "\n",
    "class Decoder_part1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer23 = nn.Sequential(\n",
    "            ResnetBlock(56,56),\n",
    "            ResnetBlock(56,48)\n",
    "        )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            ResnetBlock(96,48),\n",
    "            ResnetBlock(48,48),\n",
    "            ResnetBlock(48,40)\n",
    "        )\n",
    "        self.layer21 = nn.Sequential(\n",
    "            ResnetBlock(80,40),\n",
    "            ResnetBlock(40,40),\n",
    "            ResnetBlock(40,32)\n",
    "        )\n",
    "        self.layer20 = nn.Sequential(\n",
    "            ResnetBlock(64,32),\n",
    "            ResnetBlock(32,32)\n",
    "        )\n",
    "        self.transposeConv = nn.ConvTranspose3d(32,16,kernel_size=2,stride=2)\n",
    "        self.layer10 = nn.Conv3d(17,16,kernel_size=3,padding=1)\n",
    "\n",
    "    def forward(self,x,x0,x1,x2,x3):\n",
    "        \n",
    "        y=self.layer23(x3)\n",
    "        y=t.cat([y,x2],dim=1)\n",
    "        y=self.layer22(y)\n",
    "        y=t.cat([y,x1],dim=1)\n",
    "        y=self.layer21(y)\n",
    "        y=t.cat([y,x0],dim=1)\n",
    "        y=self.layer20(y)\n",
    "        y=self.transposeConv(y)\n",
    "        y=t.cat([y,x],dim=1)\n",
    "        y=self.layer10(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "\n",
    "\n",
    "class NetCore(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder_part1 = Decoder_part1()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x,x0,x1,x2,x3=self.encoder(x)\n",
    "        y=self.decoder_part1(x,x0,x1,x2,x3)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ResUNetModel(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = NetCore()\n",
    "        self.finalConv = nn.Sequential(\n",
    "            nn.Conv3d(16,8,1),\n",
    "            nn.Softmax(dim=1),\n",
    "        ).cuda()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        y=self.core(x)\n",
    "        y=self.finalConv(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bce26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 20\n"
     ]
    }
   ],
   "source": [
    "#dataloading\n",
    "class HaN_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir=None, transform=False, alpha=1000, sigma=30, alpha_affine=0.04):\n",
    "        super().__init__()\n",
    "        self.path = root_dir\n",
    "        self.datas = t.load(self.path)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.alpha_affine = alpha_affine\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.datas[index]\n",
    "        img = data['img'].numpy().astype(np.float32)\n",
    "        \n",
    "        if not self.transform:\n",
    "            masklst = []\n",
    "            for mask in data['mask']:\n",
    "                if mask is None:\n",
    "                    mask = np.zeros((1,img.shape[0],img.shape[1],img.shape[2])).astype(np.uint8)\n",
    "                masklst.append(mask.astype(np.uint8).reshape((1,img.shape[0],img.shape[1],img.shape[2]))) \n",
    "            mask0 = np.zeros_like(masklst[0]).astype(np.uint8)\n",
    "            for mask in masklst:\n",
    "                mask0 = np.logical_or(mask0, mask).astype(np.uint8)\n",
    "            mask0 = 1 - mask0\n",
    "            return t.from_numpy(img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))), t.from_numpy(np.concatenate([mask0]+masklst, axis=0)), True\n",
    "        \n",
    "        im_merge = np.concatenate([img[...,None]]+[mask.astype(np.float32)[...,None] for mask in data['mask']], axis=3)\n",
    "        # Apply transformation on image\n",
    "        im_merge_t, new_img = self.elastic_transform3Dv2(im_merge,self.alpha,self.sigma,min(im_merge.shape[1:-1])*self.alpha_affine)\n",
    "        # Split image and mask ::2, ::2, ::2\n",
    "        im_t = im_merge_t[...,0]\n",
    "        im_mask_t = im_merge_t[..., 1:].astype(np.uint8).transpose(3, 0, 1, 2)\n",
    "        mask0 = np.zeros_like(im_mask_t[0, :, :, :]).reshape((1,)+im_mask_t.shape[1:]).astype(np.uint8)\n",
    "        im_mask_t_lst = []\n",
    "        flagvect = np.ones((8,), np.float32)\n",
    "        retflag = True\n",
    "        for i in range(7):\n",
    "            im_mask_t_lst.append(im_mask_t[i,:,:,:].reshape((1,)+im_mask_t.shape[1:]))\n",
    "            if im_mask_t[i,:,:,:].max() != 1: \n",
    "                retflag = False\n",
    "                flagvect[i+1] = 0\n",
    "            mask0 = np.logical_or(mask0, im_mask_t[i,:,:,:]).astype(np.uint8)\n",
    "        if not retflag: flagvect[0] = 0\n",
    "        mask0 = 1 - mask0\n",
    "        return t.from_numpy(im_t.reshape((1,)+im_t.shape[:3])), t.from_numpy(np.concatenate([mask0]+im_mask_t_lst, axis=0)), flagvect\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def elastic_transform3Dv2(self, image, alpha, sigma, alpha_affine, random_state=None):\n",
    "        \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
    "        .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "             Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "             Proc. of the International Conference on Document Analysis and\n",
    "             Recognition, 2003.\n",
    "         Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "         From https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation\n",
    "        \"\"\"\n",
    "        # affine and deformation must be slice by slice and fixed for slices\n",
    "        if random_state is None:\n",
    "            random_state = np.random.RandomState(None)\n",
    "        shape = image.shape # image is contatenated, the first channel [:,:,:,0] is the image, the second channel \n",
    "        # [:,:,:,1] is the mask. The two channel are under the same tranformation.\n",
    "        shape_size = shape[:-1] # z y x\n",
    "        # Random affine\n",
    "        shape_size_aff = shape[1:-1] # y x\n",
    "        center_square = np.float32(shape_size_aff) // 2\n",
    "        square_size = min(shape_size_aff) // 3\n",
    "        pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "        pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        new_img = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img[i,:,:,0] = cv2.warpAffine(image[i,:,:,0], M, shape_size_aff[::-1], borderMode=cv2.BORDER_CONSTANT, borderValue=0.)\n",
    "            for j in range(1, 8):\n",
    "                new_img[i,:,:,j] = cv2.warpAffine(image[i,:,:,j], M, shape_size_aff[::-1], flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_TRANSPARENT, borderValue=0)\n",
    "        dx = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        x, y = np.meshgrid(np.arange(shape_size_aff[1]), np.arange(shape_size_aff[0]))\n",
    "        indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "        new_img2 = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img2[i,:,:,0] = map_coordinates(new_img[i,:,:,0], indices, order=1, mode='constant').reshape(shape[1:-1])\n",
    "            for j in range(1, 8):\n",
    "                new_img2[i,:,:,j] = map_coordinates(new_img[i,:,:,j], indices, order=0, mode='constant').reshape(shape[1:-1])\n",
    "        return np.array(new_img2), new_img\n",
    "# %%\n",
    "\n",
    "\n",
    "traindataset = HaN_Dataset(train_path, transform=True)\n",
    "traindataloader = DataLoader(traindataset, batch_size=1, shuffle=True)\n",
    "testdataset = HaN_Dataset(test_path, transform=False)\n",
    "testdataloader = DataLoader(testdataset, batch_size=1)\n",
    "\n",
    "print(len(traindataloader),len(testdataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fc6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def crossentropy(y_pred, y_true, flagvec, device):\n",
    "    retv = - t.sum(t.sum(t.sum(t.sum(t.log(t.clamp(y_pred,1e-6,1))*y_true.type(t.cuda.FloatTensor),4),3),2),0) * flagvec.to(device)\n",
    "    return t.sum(retv / (t.sum(t.sum(t.sum(t.sum(y_true.type(t.cuda.FloatTensor),4),3),2),0) + 1e-6)) / y_true.size()[1]\n",
    "\n",
    "# %%\n",
    "\n",
    "def tversky_loss_wmask(y_pred, y_true, flagvec, device):\n",
    "    alpha = 0.5\n",
    "    beta  = 0.5\n",
    "    ones = t.ones_like(y_pred) \n",
    "\n",
    "    p0 = y_pred      # proba that voxels are class i\n",
    "    p1 = ones-y_pred # proba that voxels are not class i\n",
    "    g0 = y_true.type(t.cuda.FloatTensor)\n",
    "    g1 = ones-g0\n",
    "    num = t.sum(t.sum(t.sum(t.sum(p0*g0, 4),3),2),0) #(0,2,3,4)) #K.sum(p0*g0, (0,1,2,3))\n",
    "    den = num + alpha*t.sum(t.sum(t.sum(t.sum(p0*g1,4),3),2),0) + beta*t.sum(t.sum(t.sum(t.sum(p1*g0,4),3),2),0) #(0,2,3,4))\n",
    "\n",
    "    T = t.sum((num* flagvec.to(device))/(den+1e-5))\n",
    "    return t.sum(flagvec.to(device))-T\n",
    "\n",
    "# %%\n",
    "\n",
    "def focal(y_pred, y_true, flagvec, device):\n",
    "    retv = - t.mean(t.mean(t.mean(t.mean(t.log(t.clamp(y_pred,1e-6,1))*y_true.type(t.cuda.FloatTensor)*t.pow(1-y_pred,2),4),3),2),0) * flagvec.to(device)\n",
    "    return t.sum(retv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a4218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSC evaluation\n",
    "def caldice(y_pred, y_true):\n",
    "\n",
    "    y_pred = y_pred.data.cpu().numpy().transpose(1,0,2,3,4) # inference should be arg max\n",
    "    y_pred = np.argmax(y_pred, axis=0).squeeze() # z y x\n",
    "    y_true = y_true.data.cpu().numpy().transpose(1,0,2,3,4).squeeze() # .cpu()\n",
    "    avgdice = []\n",
    "    y_pred_1 = y_pred==1\n",
    "    y_true_1 = y_true[1,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==2\n",
    "    y_true_1 = y_true[2,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==3\n",
    "    y_true_1 = y_true[3,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==4\n",
    "    y_true_1 = y_true[4,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==5\n",
    "    y_true_1 = y_true[5,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==6\n",
    "    y_true_1 = y_true[6,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "    \n",
    "    y_pred_1 = y_pred==7\n",
    "    y_true_1 = y_true[7,:,:,:]\n",
    "    if y_pred_1.sum() + y_true_1.sum() == 0: avgdice.append(-1)\n",
    "    else: avgdice.append(2.*(np.logical_and(y_pred_1, y_true_1).sum()) / (1.0*(y_pred_1.sum() + y_true_1.sum())))\n",
    "\n",
    "    for dice in avgdice: \n",
    "        if dice != -1:\n",
    "            assert 0 <= dice <= 1\n",
    "    return avgdice\n",
    "\n",
    "def get_yPredDash(y_pred):\n",
    "    \n",
    "    y_pred = y_pred.data.cpu().numpy() # inference should be arg max\n",
    "    y_pred_1 = np.zeros_like(y_pred).astype(np.uint8)\n",
    "    y_pred = np.argmax(y_pred, axis=1).squeeze() # z y x\n",
    "    \n",
    "    for i in range(8):\n",
    "        y_pred_1[:,i,:,:,:] = y_pred==i\n",
    "    \n",
    "    return y_pred_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755b7289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUNetmodel created\n"
     ]
    }
   ],
   "source": [
    "#ResUnet\n",
    "file_name = \"ResUNet_dice_log_tcia.txt\"\n",
    "file_name_1 = \"ResUNet_loss_log_tcia.txt\"\n",
    "file_name_2 = \"ResUNet_totalDice_log_tcia.txt\"\n",
    "epoch150_path_name = \"Weights/ResUNet_epoch150_path\"\n",
    "epoch150_50_path_name = \"Weights/ResUNet_epoch150_50_path\"\n",
    "\n",
    "\n",
    "UNet_Model = ResUNetModel()\n",
    "print(\"ResUNetmodel created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb8b8cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:13<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  8.019301193105873 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.005945: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 10.471872038021683\n",
      "epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:07<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  7.198438120311125 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.076190: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 9.425079122371972\n",
      "epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:07<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  6.256445101816826 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.430075: 100%|██████████████████████| 20/20 [00:11<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 6.508523789048195\n",
      "epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:05<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  4.931549442112964 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.349539: 100%|██████████████████████| 20/20 [00:12<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 7.598909487016499\n",
      "epoch  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:10<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  4.22099498416445 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.306582: 100%|██████████████████████| 20/20 [00:12<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 7.560581266134977\n",
      "epoch  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:07<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.8806611068453805 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.456489: 100%|██████████████████████| 20/20 [00:12<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 5.90047484152019\n",
      "epoch  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:09<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.6806680102562543 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.215615: 100%|██████████████████████| 20/20 [00:12<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.523192312195897\n",
      "epoch  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:08<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.495402320680127 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.518789: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.988463223166764\n",
      "epoch  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:08<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.2945625480680705 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.327384: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 6.611642868071795\n",
      "epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:05<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.1768364533238893 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.017525: 100%|██████████████████████| 20/20 [00:12<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 10.064831685647368\n",
      "epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:05<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  3.000292162659056 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.544217: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.602844662219286\n",
      "epoch  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:03<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.870409030871346 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.675790: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.685822298377752\n",
      "epoch  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:31<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.7168212921820167 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.382752: 100%|██████████████████████| 20/20 [00:12<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 6.2801226550713185\n",
      "epoch  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:49<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.6412752636981978 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.697194: 100%|██████████████████████| 20/20 [00:12<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.0844399915076792\n",
      "epoch  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:52<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.542480454619952 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.684740: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.129079524241388\n",
      "epoch  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:30<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.43604290149888 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.676360: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.277706319373101\n",
      "epoch  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:35<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.424584675440537 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.561441: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.620764555595815\n",
      "epoch  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:31<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.3945351906385746 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.762359: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.7615641456097366\n",
      "epoch  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:32<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.292263032830435 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.762680: 100%|██████████████████████| 20/20 [00:12<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.821310202870518\n",
      "epoch  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:30<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.2766820141891544 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.718908: 100%|██████████████████████| 20/20 [00:12<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.0679695181548596\n",
      "epoch  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:32<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.242453527454479 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.763209: 100%|██████████████████████| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.613476653769612\n",
      "epoch  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:33<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.1979967172694024 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.729323: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.7806276116520166\n",
      "epoch  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:31<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.1545422970634824 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.671160: 100%|██████████████████████| 20/20 [00:12<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.6694961907342076\n",
      "epoch  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:26<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.1411656453255916 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.711745: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.72274017566815\n",
      "epoch  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:27<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.108090957974981 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.757654: 100%|██████████████████████| 20/20 [00:11<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.563398497924209\n",
      "epoch  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:28<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.083923399402877 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.741832: 100%|██████████████████████| 20/20 [00:12<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.783161276765168\n",
      "epoch  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:31<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.047296700635274 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.803679: 100%|██████████████████████| 20/20 [00:12<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.5608563052956015\n",
      "epoch  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:31<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.0511272425274476 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.726112: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.854386712796986\n",
      "epoch  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:23<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.041255915856791 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.730438: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.603168218676001\n",
      "epoch  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:23<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.0047924212698773 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.774232: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.4462067036889494\n",
      "epoch  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:10<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9932651419185103 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.756209: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.547630455903709\n",
      "epoch  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9812737576512733 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.718327: 100%|██████████████████████| 20/20 [00:11<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.9780101066455247\n",
      "epoch  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:00<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9520195421653936 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.798824: 100%|██████████████████████| 20/20 [00:12<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.3877323587425052\n",
      "epoch  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:01<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9430403850058295 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.772109: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.7484818219207225\n",
      "epoch  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:32<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.9266017865316758 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.724165: 100%|██████████████████████| 20/20 [00:12<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 3.1881018252111972\n",
      "epoch  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:22<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.911698439978579 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.567780: 100%|██████████████████████| 20/20 [00:12<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 4.212796698138118\n",
      "epoch  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:21<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.900942066376775 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.743640: 100%|██████████████████████| 20/20 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.6016263009980323\n",
      "epoch  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:32<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8710262208557837 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.783236: 100%|██████████████████████| 20/20 [00:12<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.4282512275502084\n",
      "epoch  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:18<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.862434833601031 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.781282: 100%|██████████████████████| 20/20 [00:12<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.449630775395781\n",
      "epoch  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:24<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8720592848566373 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.697831: 100%|██████████████████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.8323196235112844\n",
      "epoch  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:25<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.847869754296488 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.746562: 100%|██████████████████████| 20/20 [00:12<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.572577742766589\n",
      "epoch  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [10:25<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  1.8337857894969374 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice value 0.790461: 100%|██████████████████████| 20/20 [00:11<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.3373431260697544\n",
      "epoch  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▉                            | 70/211 [03:27<06:57,  2.96s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2426/1507334064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mceweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mceloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfocweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mceweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mceloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfocweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             F.rmsprop(params_with_grad,\n\u001b[0m\u001b[1;32m    136\u001b[0m                       \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                       \u001b[0msquare_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36mrmsprop\u001b[0;34m(params, grads, square_avgs, grad_avgs, momentum_buffer_list, lr, alpha, eps, weight_decay, momentum, centered)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ResUnet  training\n",
    "epoch1=150\n",
    "epoch2=50\n",
    "UNet_Model = ResUNetModel()\n",
    "model=UNet_Model.to(device)\n",
    "\n",
    "lossweight = np.array([2.22, 1.06, 1.02, 1.74, 1.93, 1.93, 1.13, 1.15], np.float32)\n",
    "ceweight = 0.05\n",
    "focweight = 0.5\n",
    "\n",
    "optimizer = t.optim.RMSprop(model.parameters(),lr = 2e-3)\n",
    "\n",
    "#for epoch in range(anatomy_epoch1):\n",
    "for epoch in range(epoch1):\n",
    "    i=0\n",
    "    j=0\n",
    "    train_loss = 0\n",
    "    print(\"epoch \", epoch+1)\n",
    "    for x_train, y_train, flagvec in tqdm.tqdm(traindataloader):\n",
    "        \n",
    "        i+=1\n",
    "        model.train()\n",
    "        #print(f'epoch {epoch+1} batch {i} tensor_shape {x_train.shape}')\n",
    "        if x_train.shape[-2] > 300:\n",
    "            x_train = x_train[...,10:,:]\n",
    "            y_train = y_train[...,10:,:]\n",
    "        \n",
    "        x_train = x_train.to(device1)\n",
    "        out =model(x_train)\n",
    "        \n",
    "        out = out.to(device2)\n",
    "        y_train = y_train.to(device2)\n",
    "        loss = tversky_loss_wmask(out, y_train, flagvec*t.from_numpy(lossweight), device2)\n",
    "        celoss = crossentropy(out, y_train, flagvec*t.from_numpy(lossweight), device2)\n",
    "        floss = focal(out, y_train, flagvec*t.from_numpy(lossweight), device2)\n",
    "        optimizer.zero_grad()\n",
    "        (loss + (ceweight*celoss) + (focweight*floss)).backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() + (ceweight*celoss).item() + (focweight*floss).item()\n",
    "\n",
    "        y_train.detach_()\n",
    "        out.detach_()\n",
    "        del loss, x_train, y_train, out, floss, celoss\n",
    "        \n",
    "    print(\"train loss: \",train_loss/(len(traindataloader)-j),'\\n')\n",
    "    \n",
    "    testtq = tqdm.tqdm(testdataloader)#, desc='loss', leave=True)\n",
    "    test_loss = 0\n",
    "    testloss = [0 for _ in range(7)]\n",
    "    for x_test, y_test, flagvecTest in testtq:\n",
    "        with t.no_grad():\n",
    "            model.eval()\n",
    "            x_test = x_test.to(device1)\n",
    "            y_test = y_test.to(device2)\n",
    "            out = model(x_test)\n",
    "            out = out.to(device2)\n",
    "            loss = tversky_loss_wmask(out, y_test, flagvecTest*t.from_numpy(lossweight), device2)\n",
    "            celoss = crossentropy(out, y_test, flagvecTest*t.from_numpy(lossweight), device2)\n",
    "            floss = focal(out, y_test, flagvecTest*t.from_numpy(lossweight), device2)\n",
    "            test_loss += loss.item() + (ceweight*celoss).item() + (focweight*floss).item()\n",
    "            dice= caldice(out, y_test)\n",
    "            testtq.set_description(\"dice value %f\" % (sum(dice)/7))\n",
    "            testtq.refresh()\n",
    "            testloss = [l+tl if l != -1 else tl for l,tl in zip(dice, testloss)]\n",
    "            del out, x_test, y_test\n",
    "            \n",
    "    print(f\"test loss: {test_loss/len(testdataloader)}\")\n",
    "    \n",
    "    with open(file_name_1, \"a\") as f:\n",
    "        f.write(f\"epoch {epoch+1}\")\n",
    "        f.write(f\"\\ttrain loss: {train_loss/(len(traindataloader)-j)}\")\n",
    "        f.write(f\"\\ttest loss: {test_loss/len(testdataloader)}\\n\")\n",
    "                           \n",
    "    testloss = [l / len(testtq) for l in testloss]\n",
    "    with open(file_name_2, \"a\") as f:\n",
    "        f.write(f\"epoch {epoch+1}\")\n",
    "        f.write('\\tDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "            \n",
    "    if (epoch+1)%10==0:\n",
    "        \n",
    "        t.save({\n",
    "        'epoch': epoch+1,\n",
    "        'model_state_dict':  model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, epoch150_path_name)\n",
    "        \n",
    "        with open(file_name, \"a\") as f:\n",
    "            f.write(f\"epoch {epoch+1}\")\n",
    "            f.write('\\tDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))\n",
    "        \n",
    "        for x,y,_ in testdataloader:\n",
    "            with t.no_grad():\n",
    "                y_pred = model(x.to(device1))\n",
    "                y_predDash = get_yPredDash(y_pred)\n",
    "                np.save(y_pred_path,y_predDash)\n",
    "                np.save(y_true_path,y.cpu())\n",
    "                #print(y_pred.shape, y.shape) \n",
    "                break\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "760207ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#evaluation Step1\n",
    "weight_path= \"Weights/ResUnet_tcia_42.pth\"\n",
    "UNet_Model =  ResUNetModel()\n",
    "loaded_model = t.load(weight_path, map_location='cuda:0')\n",
    "print(loaded_model[\"epoch\"])\n",
    "UNet_Model.load_state_dict(loaded_model[\"model_state_dict\"])\n",
    "model=UNet_Model.to(device)\n",
    "\n",
    "testdataset = HaN_Dataset(test_path, transform=False)\n",
    "testdataloader = DataLoader(testdataset, batch_size=1)\n",
    "print(len(testdataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20ece847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss 0.769712: 100%|███████████████████████| 20/20 [00:11<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDice coeff 0.8209, 0.5709, 0.9189, 0.6950, 0.7416, 0.8063, 0.8432 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluation Step2\n",
    "testloss = [0 for _ in range(7)]\n",
    "testtq = tqdm.tqdm(testdataloader, desc='loss', leave=True)\n",
    "   \n",
    "for x_test, y_test, _ in testtq:\n",
    "    with t.no_grad():\n",
    "        model.eval()\n",
    "        x_test = x_test.to(device1) \n",
    "        y_test = y_test.to(device2) \n",
    "        o = model(x_test)\n",
    "        o = o.to(device2) \n",
    "        loss = caldice(o, y_test)\n",
    "        testtq.set_description(\"test loss %f\" % (sum(loss)/7))\n",
    "        testtq.refresh() \n",
    "        testloss = [l+tl if l != -1 else tl for l,tl in zip(loss, testloss)]  \n",
    "        del x_test, y_test, o\n",
    "        \n",
    "testloss = [l / len(testtq) for l in testloss]\n",
    "print('\\tDice coeff %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f \\n' % tuple(testloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7a083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
