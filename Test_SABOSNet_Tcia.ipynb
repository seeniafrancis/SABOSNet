{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198904de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 30 05:43:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    61W / 275W |  19389MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   55C    P0   262W / 275W |  17111MiB / 40536MiB |     93%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    60W / 275W |   7238MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7a5226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchio in /home/seenia/.local/lib/python3.6/site-packages (0.18.68)\n",
      "Requirement already satisfied: tqdm in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (4.54.1)\n",
      "Requirement already satisfied: Deprecated in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (1.2.12)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from torchio) (6.7)\n",
      "Requirement already satisfied: SimpleITK!=2.0.* in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (2.1.1)\n",
      "Requirement already satisfied: humanize in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (3.5.0)\n",
      "Requirement already satisfied: torch>=1.1 in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (1.5.4)\n",
      "Requirement already satisfied: nibabel in /home/seenia/.local/lib/python3.6/site-packages (from torchio) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions in /home/seenia/.local/lib/python3.6/site-packages (from torch>=1.1->torchio) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /home/seenia/.local/lib/python3.6/site-packages (from torch>=1.1->torchio) (0.8)\n",
      "Requirement already satisfied: future in /home/seenia/.local/lib/python3.6/site-packages (from torch>=1.1->torchio) (0.18.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/seenia/.local/lib/python3.6/site-packages (from Deprecated->torchio) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /home/seenia/.local/lib/python3.6/site-packages (from humanize->torchio) (51.0.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/seenia/.local/lib/python3.6/site-packages (from nibabel->torchio) (20.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=14.3->nibabel->torchio) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f3062e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting monai\n",
      "  Downloading monai-0.8.0-202111251823-py3-none-any.whl (709 kB)\n",
      "\u001b[K     |████████████████████████████████| 709 kB 269 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from monai) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->monai) (3.10.0.2)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf8e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm\n",
    "import random\n",
    "import copy\n",
    "import torchio\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e7d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.backends.cudnn.enabled = True\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "#device = \"cuda:0\"\n",
    "#device1 = \"cuda:0\"\n",
    "#device2 = \"cuda:0\"\n",
    "\n",
    "#train_path = \"../../train_data_tcia.pth\"\n",
    "\n",
    "test_path = \"Data/test_data_tcia.pth\"\n",
    "\n",
    "y_pred_path = \"OutputsTcia/SABOSpred_tcia\"\n",
    "y_true_path = \"OutputsTcia/SABOStrue_tcia\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd23e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encoder - Decoder Network\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return t.cat((t.max(x,1)[0].unsqueeze(1), t.mean(x,1).unsqueeze(1)),dim=1)\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.compress = ChannelPool()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(2,1,kernel_size=7,stride=1,padding=3, bias=False),\n",
    "            nn.BatchNorm3d(1,eps=1e-5,momentum=0.01,affine=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        xcompress=self.compress(x)\n",
    "        spatialAttention=self.conv(xcompress)\n",
    "        return x*spatialAttention\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "  \n",
    "    def __init__(self,channels,reductionRatio=16,poolTypes=['avg','max']):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(channels,channels//reductionRatio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels//reductionRatio,channels)\n",
    "        )\n",
    "        self.poolTypes = poolTypes\n",
    "  \n",
    "    def forward(self,x):\n",
    "        attentionSum = None\n",
    "        for poolType in self.poolTypes:\n",
    "            if poolType=='avg':\n",
    "                avgPool = F.avg_pool3d(x,(x.size(2),x.size(3),x.size(4)),stride=(x.size(2),x.size(3),x.size(4)))\n",
    "                channelAttention = self.mlp(avgPool)\n",
    "            if poolType=='max':\n",
    "                maxPool = F.max_pool3d(x,(x.size(2),x.size(3),x.size(4)),stride=(x.size(2),x.size(3),x.size(4)))\n",
    "                channelAttention = self.mlp(maxPool)\n",
    "        if attentionSum is None:\n",
    "              attentionSum = channelAttention\n",
    "        else:\n",
    "              attentionSum=attentionSum+channelAttention\n",
    "    \n",
    "        scale=t.sigmoid(attentionSum).unsqueeze(2).unsqueeze(3).unsqueeze(4).expand_as(x)\n",
    "        return x*scale\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "  \n",
    "    def __init__(self,channels,reductionRatio=16,poolTypes=['avg','max']):\n",
    "        super().__init__()\n",
    "        self.channelGate = ChannelGate(channels,reductionRatio,poolTypes)\n",
    "        self.spatialGate = SpatialGate()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.spatialGate(x)\n",
    "        x=self.channelGate(x)\n",
    "        return x \n",
    "    \n",
    "class CBAMResnetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,kernelSize=3):\n",
    "        super().__init__()\n",
    "        self.resnetblock1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "        self.resnetblock2 = nn.Sequential(\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv3d(out_channels,out_channels,kernel_size=kernelSize,padding=1),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "        self.CBAM = CBAM(out_channels,16,['avg','max'])\n",
    "        self.reluUnit = nn.Sequential(\n",
    "            nn.ReLU(inplace=False)\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.resnetblock1(x)\n",
    "        x1=x\n",
    "        x=self.resnetblock2(x)\n",
    "        x=self.CBAM(x)\n",
    "        x=x+x1\n",
    "        x=self.reluUnit(x)\n",
    "        return x\n",
    "    \n",
    "class GSEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.downConv  = nn.Sequential(\n",
    "            nn.Conv3d(1,32,kernel_size=3,stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "        self.layer21 = nn.Sequential(\n",
    "            CBAMResnetBlock(32,40),\n",
    "            CBAMResnetBlock(40,40)\n",
    "        )\n",
    "\n",
    "        self.layer22 = nn.Sequential(\n",
    "            CBAMResnetBlock(40,48),\n",
    "            CBAMResnetBlock(48,48)\n",
    "        )\n",
    "\n",
    "        self.layer23 = CBAMResnetBlock(48,56)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x0=self.downConv(x)\n",
    "        x1=self.layer21(x0)\n",
    "        x2=self.layer22(x1)\n",
    "        x3=self.layer23(x2)\n",
    "        #print(x3.shape)\n",
    "        return x,x0,x1,x2,x3\n",
    "\n",
    "\n",
    "class GSDecoder_part1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer23 = nn.Sequential(\n",
    "            CBAMResnetBlock(56,56),\n",
    "            CBAMResnetBlock(56,48)\n",
    "        )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            CBAMResnetBlock(96,48),\n",
    "            CBAMResnetBlock(48,48),\n",
    "            CBAMResnetBlock(48,40)\n",
    "        )\n",
    "        self.layer21 = nn.Sequential(\n",
    "            CBAMResnetBlock(80,40),\n",
    "            CBAMResnetBlock(40,40),\n",
    "            CBAMResnetBlock(40,32)\n",
    "        )\n",
    "        self.layer20 = nn.Sequential(\n",
    "            CBAMResnetBlock(64,32),\n",
    "            CBAMResnetBlock(32,32)\n",
    "        )\n",
    "        self.transposeConv = nn.ConvTranspose3d(32,16,kernel_size=2,stride=2)\n",
    "        self.layer10 = nn.Conv3d(17,16,kernel_size=3,padding=1)\n",
    "\n",
    "    def forward(self,x,x0,x1,x2,x3):\n",
    "        \n",
    "        y=self.layer23(x3)\n",
    "        y=t.cat([y,x2],dim=1)\n",
    "        y=self.layer22(y)\n",
    "        y=t.cat([y,x1],dim=1)\n",
    "        y=self.layer21(y)\n",
    "        y=t.cat([y,x0],dim=1)\n",
    "        y=self.layer20(y)\n",
    "        y=self.transposeConv(y)\n",
    "        y=t.cat([y,x],dim=1)\n",
    "        y=self.layer10(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "\n",
    "\n",
    "class GSNetCore(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = GSEncoder()\n",
    "        self.decoder_part1 = GSDecoder_part1()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x,x0,x1,x2,x3=self.encoder(x)\n",
    "        y=self.decoder_part1(x,x0,x1,x2,x3)\n",
    "        return y\n",
    "\n",
    "\n",
    "class GSNetModel(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = GSNetCore()\n",
    "        self.finalConv = nn.Sequential(\n",
    "            nn.Conv3d(16,8,1),\n",
    "            nn.Softmax(dim=1),\n",
    "        ).cuda()\n",
    "  \n",
    "    def forward(self,x):\n",
    "        y=self.core(x)\n",
    "        y=self.finalConv(y)\n",
    "        #print(y.shape)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb249ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaN_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir=None, transform=False, alpha=1000, sigma=30, alpha_affine=0.04):\n",
    "        super().__init__()\n",
    "        self.path = root_dir\n",
    "        self.datas = t.load(self.path)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.alpha_affine = alpha_affine\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.datas[index]\n",
    "        img = data['img'].numpy().astype(np.float32)\n",
    "        \n",
    "        if not self.transform:\n",
    "            masklst = []\n",
    "            for mask in data['mask']:\n",
    "                if mask is None:\n",
    "                    mask = np.zeros((1,img.shape[0],img.shape[1],img.shape[2])).astype(np.uint8)\n",
    "                masklst.append(mask.astype(np.uint8).reshape((1,img.shape[0],img.shape[1],img.shape[2]))) \n",
    "            mask0 = np.zeros_like(masklst[0]).astype(np.uint8)\n",
    "            for mask in masklst:\n",
    "                mask0 = np.logical_or(mask0, mask).astype(np.uint8)\n",
    "            mask0 = 1 - mask0\n",
    "            return t.from_numpy(img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))), t.from_numpy(np.concatenate([mask0]+masklst, axis=0)), True\n",
    "        \n",
    "       \n",
    "        im_merge = np.concatenate([img[...,None]]+[mask.astype(np.float32)[...,None] for mask in data['mask']], axis=3)\n",
    "        # Apply transformation on image\n",
    "        im_merge_t, new_img = self.elastic_transform3Dv2(im_merge,self.alpha,self.sigma,min(im_merge.shape[1:-1])*self.alpha_affine)\n",
    "        # Split image and mask ::2, ::2, ::2\n",
    "        im_t = im_merge_t[...,0]\n",
    "        im_mask_t = im_merge_t[..., 1:].astype(np.uint8).transpose(3, 0, 1, 2)\n",
    "        mask0 = np.zeros_like(im_mask_t[0, :, :, :]).reshape((1,)+im_mask_t.shape[1:]).astype(np.uint8)\n",
    "        im_mask_t_lst = []\n",
    "        flagvect = np.ones((8,), np.float32)\n",
    "        retflag = True\n",
    "        for i in range(7):\n",
    "            im_mask_t_lst.append(im_mask_t[i,:,:,:].reshape((1,)+im_mask_t.shape[1:]))\n",
    "            if im_mask_t[i,:,:,:].max() != 1: \n",
    "                retflag = False\n",
    "                flagvect[i+1] = 0\n",
    "            mask0 = np.logical_or(mask0, im_mask_t[i,:,:,:]).astype(np.uint8)\n",
    "        if not retflag: flagvect[0] = 0\n",
    "        mask0 = 1 - mask0\n",
    "        return t.from_numpy(im_t.reshape((1,)+im_t.shape[:3])), t.from_numpy(np.concatenate([mask0]+im_mask_t_lst, axis=0)), flagvect\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def elastic_transform3Dv2(self, image, alpha, sigma, alpha_affine, random_state=None):\n",
    "        \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
    "        .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "             Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "             Proc. of the International Conference on Document Analysis and\n",
    "             Recognition, 2003.\n",
    "         Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "         From https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation\n",
    "        \"\"\"\n",
    "        # affine and deformation must be slice by slice and fixed for slices\n",
    "        if random_state is None:\n",
    "            random_state = np.random.RandomState(None)\n",
    "        shape = image.shape # image is contatenated, the first channel [:,:,:,0] is the image, the second channel \n",
    "        # [:,:,:,1] is the mask. The two channel are under the same tranformation.\n",
    "        shape_size = shape[:-1] # z y x\n",
    "        # Random affine\n",
    "        shape_size_aff = shape[1:-1] # y x\n",
    "        center_square = np.float32(shape_size_aff) // 2\n",
    "        square_size = min(shape_size_aff) // 3\n",
    "        pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "        pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        new_img = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img[i,:,:,0] = cv2.warpAffine(image[i,:,:,0], M, shape_size_aff[::-1], borderMode=cv2.BORDER_CONSTANT, borderValue=0.)\n",
    "            for j in range(1, 8):\n",
    "                new_img[i,:,:,j] = cv2.warpAffine(image[i,:,:,j], M, shape_size_aff[::-1], flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_TRANSPARENT, borderValue=0)\n",
    "        dx = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape[1:-1]) * 2 - 1), sigma) * alpha\n",
    "        x, y = np.meshgrid(np.arange(shape_size_aff[1]), np.arange(shape_size_aff[0]))\n",
    "        indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "        new_img2 = np.zeros_like(image)\n",
    "        for i in range(shape[0]):\n",
    "            new_img2[i,:,:,0] = map_coordinates(new_img[i,:,:,0], indices, order=1, mode='constant').reshape(shape[1:-1])\n",
    "            for j in range(1, 8):\n",
    "                new_img2[i,:,:,j] = map_coordinates(new_img[i,:,:,j], indices, order=0, mode='constant').reshape(shape[1:-1])\n",
    "        return np.array(new_img2), new_img\n",
    "      \n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae0656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yPredDash(y_pred):\n",
    "    \n",
    "    y_pred = y_pred.data.cpu().numpy() # inference should be arg max\n",
    "    y_pred_1 = np.zeros_like(y_pred).astype(np.uint8)\n",
    "    y_pred = np.argmax(y_pred, axis=1).squeeze() # z y x\n",
    "    \n",
    "    for i in range(8):\n",
    "        y_pred_1[:,i,:,:,:] = y_pred==i\n",
    "    \n",
    "    return y_pred_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5fa78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# 1. TCIA test data loading\n",
    "test_path = \"Data/test_data_tcia.pth\"\n",
    "testdataset = HaN_Dataset(test_path, transform=False)\n",
    "testdataloader = DataLoader(testdataset, batch_size=1)\n",
    "print(len(testdataloader))\n",
    "weight_path = \"Weights/SABOSNet_tcia.pth\"\n",
    "#dsc_path = \"EvaluationMetrics/Tcia_20_DSCNew.npy\"\n",
    "hd_path= \"EvaluationMetrics/Tcia_20_HDNew.npy\"\n",
    "msd_path = \"EvaluationMetrics/Tcia_20_MSDNew.npy\"\n",
    "sen_path = \"EvaluationMetrics/Tcia_20_SENNew.npy\"\n",
    "ppv_path = \"EvaluationMetrics/Tcia_20_PPVNew.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2315a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. New Seenia Evaluation metrics TCIA\n",
    "from monai.metrics import HausdorffDistanceMetric,SurfaceDistanceMetric\n",
    "hd = HausdorffDistanceMetric(percentile=95,reduction=\"none\",include_background=False)\n",
    "msd = SurfaceDistanceMetric(include_background=True)\n",
    "def compute_performance(pred, gt):\n",
    "    #print(\"pred shape : \", pred.shape, \"Ground shape :\" , gt.shape)\n",
    "    pred=(pred>=0.5).type(t.float)\n",
    "    pred = pred.data.cpu()\n",
    "    gt = gt.data.cpu()\n",
    "    sen=[]\n",
    "    ppv=[]\n",
    "    for i in range(1,8):\n",
    "        pred1=pred[0][i]\n",
    "        gt1=gt[0][i]\n",
    "        TP = (gt1 * pred1).sum()\n",
    "        TN = ((1-gt1) * (1-pred1)).sum()\n",
    "        FP = ((1-gt1) * (pred1)).sum()\n",
    "        FN = ((gt1) * (1-pred1)).sum()\n",
    "        sen.append(TP/(TP+FN))\n",
    "        ppv.append(TP/(TP+FP))\n",
    "    sen=np.array(sen)\n",
    "    ppv=np.array(ppv)\n",
    "         \n",
    "    hds=hd(gt[:,1:,...].permute(0,1,3,4,2),pred[:,1:,...].permute(0,1,3,4,2))\n",
    "    msds=msd(gt[:,1:,...].permute(0,1,3,4,2),pred[:,1:,...].permute(0,1,3,4,2))\n",
    "    \n",
    "    hds=np.array(hds)\n",
    "    msds=np.array(msds)\n",
    "    return hds,msds,sen,ppv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4534ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight loaded\n",
      "Ready for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:50<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HD New:  [2.90798554 3.23503585 1.35604779 1.55103791 1.70838309 3.95297094\n",
      " 3.03074054] +/- [1.02746925 1.28903679 0.51101309 0.70285325 1.33091659 2.12697456\n",
      " 0.78397179]\n",
      "MSD New :  [1.04009279 0.9492215  0.40381043 0.4740463  0.43876314 1.22455971\n",
      " 1.11603386] +/- [0.33375619 0.4948407  0.13492341 0.23415994 0.17470953 0.31121918\n",
      " 0.18016656]\n",
      "Sensitivity New :  [0.8835704  0.65535367 0.9438397  0.7554432  0.7742028  0.89493835\n",
      " 0.9005798 ] +/- [0.06390476 0.1573351  0.03244483 0.15533407 0.06641252 0.08176685\n",
      " 0.05789993]\n",
      "Positive Predictive Value-PPV New :  [0.9010743  0.65017354 0.9201522  0.7320004  0.7602762  0.8287237\n",
      " 0.84882754] +/- [0.04027881 0.14747618 0.0337702  0.11709588 0.10157115 0.09763792\n",
      " 0.07081824]\n",
      "Average time :  0.024100000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluation TCIA\n",
    "import time\n",
    "SABOSNet_Model = GSNetModel().cuda()\n",
    "loaded_model = t.load(weight_path, map_location='cuda:0')\n",
    "SABOSNet_Model.load_state_dict(loaded_model[\"model_state_dict\"])\n",
    "print(\"weight loaded\")\n",
    "SABOSNet_Model.eval()\n",
    "print(\"Ready for evaluation\")\n",
    "hd = HausdorffDistanceMetric(percentile=95,reduction=\"none\",include_background=True)\n",
    "testtq = tqdm.tqdm(testdataloader)#, desc='loss', leave=True)\n",
    "predtime=[]\n",
    "\n",
    "msdsL=[]\n",
    "hdsL=[]\n",
    "senL=[]\n",
    "ppvL=[]\n",
    "i=0\n",
    "for x_test, y_test, _ in testtq:\n",
    "        with t.no_grad():\n",
    "            t1=time.time()\n",
    "            x_test = x_test.cuda()\n",
    "            y_test = y_test.cuda()\n",
    "            o = SABOSNet_Model(x_test)\n",
    "            ti=round(time.time()-t1 , 3)\n",
    "            predtime.append(ti)\n",
    "            y_predDash = get_yPredDash(o)\n",
    "            #np.save(y_pred_path + str(i) + \".npy\",y_predDash)\n",
    "            ti=round(time.time()-t1 , 3)\n",
    "            #np.save(y_true_path + str(i) + \".npy\",y_test.cpu())\n",
    "            o = o.cuda()\n",
    "            hds, msds, sen, ppv = compute_performance(o, y_test)\n",
    "            senL.append(sen)\n",
    "            ppvL.append(ppv)\n",
    "            hdsL.append(hds[0])\n",
    "            msdsL.append(msds[0])\n",
    "            i=i+1\n",
    "            del x_test, y_test, o\n",
    "        \n",
    "hdsL=np.array(hdsL)\n",
    "msdsL=np.array(msdsL)\n",
    "senL=np.array(senL)\n",
    "ppvL=np.array(ppvL)\n",
    "\n",
    "print(\"HD New: \", hdsL.mean(axis=0),\"+/-\", np.std(hdsL, axis=0))\n",
    "print(\"MSD New : \", msdsL.mean(axis=0),\"+/-\", np.std(msdsL, axis=0))\n",
    "print(\"Sensitivity New : \", senL.mean(axis=0), \"+/-\", np.std(senL, axis=0))\n",
    "print(\"Positive Predictive Value-PPV New : \", ppvL.mean(axis=0), \"+/-\", np.std(ppvL, axis=0))\n",
    "print (\"Average time : \", np.mean(predtime))\n",
    "            \n",
    "np.save(hd_path, hdsL)\n",
    "np.save(msd_path, msdsL)\n",
    "np.save(sen_path, senL)\n",
    "np.save(ppv_path, ppvL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f9740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
